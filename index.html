<!DOCTYPE html>
<html>
  <head>
    <title>BBS Cryptosuite v2023</title>
    <meta http-equiv='Content-Type' content='text/html;charset=utf-8'/>
    <!--
      === NOTA BENE ===
      For the three scripts below, if your spec resides on dev.w3 you can check them
      out in the same tree and use relative links so that they'll work offline,
     -->
    <script src='https://www.w3.org/Tools/respec/respec-w3c' class='remove'></script>
    <script class='remove' src="https://w3c.github.io/vc-data-integrity/common.js"></script>

    <script type="text/javascript" class="remove">
      const respecConfig = {
        // specification status (e.g. WD, LCWD, NOTE, etc.). If in doubt use ED.
        specStatus:           "ED",

        // the specification's short name, as in http://www.w3.org/TR/short-name/
        shortName: "vc-di-bbs",
        subtitle: "Securing Verifiable Credentials with Selective Disclosure using BBS Signatures",
        group: "vc",
        // latestVersion: "https://www.w3.org/community/reports/credentials/CG-FINAL-vc-di-bbs-20230405/",

        // if you wish the publication date to be other than today, set this
        // publishDate:  "2023-05-18",

        // if there is a previously published draft, uncomment this and set its YYYY-MM-DD date
        // and its maturity status
        // previousPublishDate:  "1977-03-15",
        // previousMaturity:  "WD",

        // if there a publicly available Editor's Draft, this is the link
        edDraftURI:           "https://w3c.github.io/vc-di-bbs/",

        // if this is a LCWD, uncomment and set the end of its review period
        // lcEnd: "2009-08-05",

        // if you want to have extra CSS, append them to this list
        // it is recommended that the respec.css stylesheet be kept
        //extraCSS:             ["spec.css", "prettify.css"],

        // editors, add as many as you like
        // only "name" is required
        editors:  [{
            name: "Greg Bernstein", url: "https://www.grotto-networking.com/",
            company: "Invited Expert", w3cid: 140479
          }, {
            name: "Manu Sporny", url: "https://digitalbazaar.com/",
            company: "Digital Bazaar", companyURL: "https://digitalbazaar.com/",
            w3cid: 41758
          }
        ],

        // extend the bibliography entries
        //localBiblio: webpayments.localBiblio,

        // wg:           "Verifiable Credentials Working Group Group",
        // URI of the public WG page
        // wgURI:        "https://www.w3.org/community/credentials/",
        // name (with the @w3c.org) of the public mailing to which comments are due
        // wgPublicList: "public-credentials",
        // URI of the patent status for this WG, for Rec-track documents
        // !!!! IMPORTANT !!!!
        // This is important for Rec-track documents, do not copy a patent URI from a random
        // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
        // Team Contact.
        // wgPatentURI:  "https://www.w3.org/community/about/agreements/cla/",

        github: "https://github.com/w3c/vc-di-bbs",

        // URI of the patent status for this WG, for Rec-track documents
        // !!!! IMPORTANT !!!!
        // This is important for Rec-track documents, do not copy a patent URI from a random
        // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
        // Team Contact.
        // wgPatentURI:  "",
        maxTocLevel: 4,
        /*preProcess: [ webpayments.preProcess ],
        alternateFormats: [ {uri: "diff-20111214.html", label: "diff to previous version"} ],
        */
        localBiblio:  {
          "RDF-DATASET-NORMALIZATION": {
            title:    "RDF Dataset Normalization 1.0",
            href:     "http://json-ld.github.io/normalization/spec/",
            authors:  ["David Longley", "Manu Sporny"],
            status:   "CGDRAFT",
            publisher:  "JSON-LD Community Group"
          },
          "RDF-CONCEPTS": {
            title:    "RDF 1.1 Concepts and Abstract Syntax",
            href:     "https://www.w3.org/TR/rdf11-concepts/",
            authors:  ["Richard Cyganiak", "David Wood", "Markus Lanthaler"],
            status:   "Recommendation",
            publisher:  "W3C"
          },
          "RDF-N-Quads": {
            title:    "RDF 1.1 N-Quads",
            href:     "http://json-ld.github.io/normalization/spec/",
            authors:  ["Gaven Carothers"],
            status:   "Recommendation",
          },
          "VC-DATA-INTEGRITY": {
            title:    "Verifiable Credential Data Integrity 1.0",
            href:     "https://www.w3.org/TR/vc-data-integrity/",
            authors:  ["David Longley", "Manu Sporny"],
            status:   "Working Draft",
            publisher:  "W3C Verifiable Credentials Working Group"
          },
          "DI-ECDSA": {
              title:    "The Elliptic Curve Digital Signature Algorithm Cryptosuites v1.0",
              href:     "https://www.w3.org/TR/vc-di-ecdsa/",
              authors:  ["David Longley", "Manu Sporny", "Marty Reed"],
              status:   "WD",
              publisher:  "W3C Verifiable Credentials Working Group"
          },
          "JSON-LD-FRAMING": {
            title:    "JSON-LD 1.1 Framing",
            href:     "https://www.w3.org/TR/json-ld11-framing",
            authors:  ["Dave Longley", "Gregg Kellogg", "Pierre-Antoine Champin"],
            status:   "Candidate Recommendation",
            publisher:  "W3C"
          },
          "JSON-LD": {
            title:    "JSON-LD 1.1",
            href:     "https://www.w3.org/TR/json-ld11",
            authors:  ["Dave Longley", "Gregg Kellogg", "Pierre-Antoine Champin"],
            status:   "Candidate Recommendation",
            publisher:  "W3C"
          },
          "VC-DATA-MODEL-2": {
            title: "Verifiable Credentials Data Model v2.0",
            href: "https://www.w3.org/TR/vc-data-model-2.0/",
            authors: [
              "Manu Sporny", "Dave Longley", "Grant Noble", "Dan Burnett",
              "Ted Thibodeau", "Brent Zundel", "David Chadwick",
              "Kyle Den Hartog"
            ],
            status: "Working Draft",
            publisher: "W3C Verifiable Credentials Working Group"
          },
          MULTIBASE: {
            title: "Multibase",
            href: "https://tools.ietf.org/html/draft-multiformats-multibase-01",
          },
          MULTICODEC: {
            title: "Multicodec",
            href: "https://github.com/multiformats/multicodec/",
          },
          "CFRG-BBS-SIGNATURE": {
            title:    "The BBS Signature Scheme",
            href:     "https://www.ietf.org/archive/id/draft-irtf-cfrg-bbs-signatures-02.html",
            authors:  ["Tobias Looker", "Vasilis Kalos", "Andrew Whitehead", "Mike Lodder"],
            status:   "Draft"
          },
          "CFRG-PAIRING-FRIENDLY": {
            title: "Pairing-Friendly Curves",
            href: "https://www.ietf.org/archive/id/draft-irtf-cfrg-pairing-friendly-curves-11.html",
            authors: ["Yumi Sakemi", "Tetsutaro Kobayashi", "Tsunekazu Saito", "Riad S. Wahby"],
            status: "Draft"
          },
          "BLS-JOSE-COSE": {
            title:    "Barreto-Lynn-Scott Elliptic Curve Key Representations for JOSE and COSE",
            href:     "https://datatracker.ietf.org/doc/draft-ietf-cose-bls-key-representations/",
            authors:  ["Michael B. Jones", "Tobias Looker"],
            status:   "Draft"
          },
          Taming_EdDSAs: {
            title: "Taming the many EdDSAs",
            href: "https://eprint.iacr.org/2020/1244",
            authors: ["Konstantinos Chalkias", "Fran√ßois Garillot", "Valeria Nikolaenko"],
            date: "2020",
            publisher: "Cryptology ePrint Archive, Paper 2020/1244",
            doi: "10.1007/978-3-030-64357-7_4"
          },
          CDL2016: {
            title: "Anonymous Attestation Using the Strong Diffie Hellman Assumption Revisited",
            href: "https://eprint.iacr.org/2016/663",
            authors: ["Jan Camenisch", "Manu Drijvers", "Anja Lehmann"],
            date: "2016",
            publisher: "Cryptology ePrint Archive, Paper 2016/663"
          },
          TZ2023: {
            title: "Revisiting BBS Signatures",
            href: "https://eprint.iacr.org/2023/275",
            authors: ["Stefano Tessaro", "Chenzhi Zhu"],
            date: "2023",
            publisher: "Cryptology ePrint Archive, Paper 2023/275"
          }
        },
        lint: {"no-unused-dfns": false},
        postProcess: [restrictRefs]
      };
    </script>
        <style>
          pre .highlight {
            font-weight: bold;
            color: green;
          }
          pre .comment {
            font-weight: bold;
            color: Gray;
          }
          .color-text {
            font-weight: bold;
            text-shadow: -1px 0 black, 0 1px black, 1px 0 black, 0 -1px black;
          }
          ol.algorithm {
            counter-reset: numsection;
            list-style-type: none;
          }
          ol.algorithm li {
            margin: 0.5em 0;
          }
          ol.algorithm li:before {
            font-weight: bold;
            counter-increment: numsection;
            content: counters(numsection, ".") ") ";
          }
              </style>
  </head>
  <body>
    <section id='abstract'>
      <p>
This specification describes a Data Integrity Cryptosuite for use when generating
digital signatures using the BBS signature scheme.
The Signature Suite utilizes BBS signatures to provide selective disclosure and
unlinkable derived proofs.
      </p>
    </section>

    <section id='sotd'>
      <p>
This is an experimental specification and is undergoing regular revisions. It
is not fit for production deployment.
      </p>
    </section>

    <section>
      <h2>Introduction</h2>
      <p>
This specification defines a cryptographic suite for the purpose of
creating, verifying, and deriving proofs using the BBS Signature Scheme in
conformance with the Data Integrity [[VC-DATA-INTEGRITY]] specification. The
BBS signature scheme directly provides for selective disclosure and unlinkable
proofs. It provides four high-level functions that work within the <i>issuer,
holder, verifier</i> model. Specifically, an issuer uses the BBS `Sign` function to
create a cryptographic value known as a "BBS signature" which is used in signing
the original credential. A holder, on receipt of
a credential signed with BBS, then verifies the credential with the BBS `Verify`
function.
      </p>
      <p>
The holder then chooses information to selectively disclose from the
received credential and uses the BBS `ProofGen` function to generate a
cryptographic value, known as a "BBS proof", which is used in creating a proof
for this "derived credential". The cryptographic "BBS proof" value is not linkable
to the original "BBS signature" and a different, unlinkable "BBS proof" can be
generated by the holder for additional "derived credentials", including any
containing the exact same information.
Finally, a verifier uses the BBS `ProofVerify` function to verify the derived
credential received from the holder.
      </p>
      <p>
Applying the BBS signature scheme to verifiable credentials involves the
processing specified in this document.
In general the suite uses the RDF Dataset Normalization Algorithm
[[RDF-DATASET-NORMALIZATION]] to transform an input document into its canonical
form. An issuer then uses selective disclosure primitives to separate the
canonical form into mandatory and non-mandatory statements. These are processed
separately with other information to serve as the inputs to the BBS `Sign`
function along with appropriate key material. This output is used to
generate a secured credential. A holder uses a set of selective disclosure
functions and the BBS `Verify` function on receipt of the credential
to ascertain validity.
      </p>
      <p>
Similarly, on receipt of a BBS signed credential, a holder uses the RDF Dataset
Normalization Algorithm [[RDF-DATASET-NORMALIZATION]] to transform an input
document into its canonical form, and then applies selective disclosure
primitives to separate the canonical form into mandatory and selectively
disclosed statements, which are appropriately processed and serve as inputs to
the BBS `ProofGen` function. Suitably processed, the output of this function
becomes the signed selectively disclosed credential sent to a verifier. Using
canonicalization and selective disclosure primitives, the verifier can then use
the BBS `verifyProof` function to validate the credential.
      </p>

      <section id="terminology">
        <h3>Terminology</h3>

        <div data-include="https://w3c.github.io/vc-data-integrity/terms.html"></div>

      </section>



      <section id="conformance">
        <p>
A <dfn>conforming proof</dfn> is any concrete expression of the data model
that complies with the normative statements in this specification. Specifically,
all relevant normative statements in Sections
<a href="#data-model"></a> and <a href="#algorithms"></a>
of this document MUST be enforced.
        </p>

        <p>
A <dfn class="lint-ignore">conforming processor</dfn> is any algorithm realized
as software and/or hardware that generates or consumes a
<a>conforming proof</a>. Conforming processors MUST produce errors when
non-conforming documents are consumed.
        </p>
	<p>
This document contains examples of JSON and JSON-LD data. Some of these examples
are invalid JSON, as they include features such as inline comments (`//`)
explaining certain portions and ellipses (`...`) indicating the omission of
information that is irrelevant to the example. Such parts need to be
removed if implementers want to treat the examples as valid JSON or JSON-LD.
        </p>
      </section>
    </section>

    <section>
      <h2>Data Model</h2>

      <p>
The following sections outline the data model that is used by this specification
for <a>verification methods</a> and <a>data integrity proof</a> formats.
      </p>

      <section>
        <h2>Verification Methods</h2>
        <p>
These verification methods are used to verify Data Integrity Proofs
[[VC-DATA-INTEGRITY]] produced using BLS12-381 cryptographic key material
that is compliant with [[CFRG-BBS-SIGNATURE]]. The encoding formats for these key types
are provided in this section. Lossless cryptographic key transformation
processes that result in equivalent cryptographic key material MAY be used
during the processing of digital signatures.
        </p>
        <section>
          <h3>Multikey</h3>
          <p>
The <a data-cite="VC-DATA-INTEGRITY#multikey">Multikey format</a>, as defined in
[[VC-DATA-INTEGRITY]], is used to express public keys for the cryptographic
suites defined in this specification.
          </p>

          <p>
The `publicKeyMultibase` property represents a Multibase-encoded Multikey
expression of a BLS12-381 public key in the G2 group. The encoding of this field
is the two-byte prefix `0xeb01` followed
by the 96-byte compressed public key data.
The 98-byte value is then encoded using base58-btc (`z`) as the prefix. Any
other encodings MUST NOT be allowed.
          </p>

          <p class="advisement">
Developers are advised to not accidentally publish a representation of a private
key. Implementations of this specification will raise errors in the event of a
[[?MULTICODEC]] value other than `0xeb01` being used in a
`publicKeyMultibase` value.
          </p>

          <pre class="example"
            title="A BLS12-381 G2 group public key, encoded as a Multikey">
{
  "id": "https://example.com/issuer/123#key-0",
  "type": "Multikey",
  "controller": "https://example.com/issuer/123",
  "publicKeyMultibase": "zUC7EK3ZakmukHhuncwkbySmomv3FmrkmS36E4Ks5rsb6VQSRpoCrx6
  Hb8e2Nk6UvJFSdyw9NK1scFXJp21gNNYFjVWNgaqyGnkyhtagagCpQb5B7tagJu3HDbjQ8h
  5ypoHjwBb"
}
          </pre>

          <pre class="example" title="A BLS12-381 G2 group public key,
          encoded as a Multikey in a controller document">
{
  "@context": [
    "https://www.w3.org/ns/did/v1",
    "https://w3id.org/security/data-integrity/v1"
  ],
  "id": "https://example.com/issuer/123",
  "verificationMethod": [{
    "id": "https://example.com/issuer/123#key-1",
    "type": "Multikey",
    "controller": "https://example.com/issuer/123",
    "publicKeyMultibase": "zUC7EK3ZakmukHhuncwkbySmomv3FmrkmS36E4Ks5rsb6VQSRpoCr
    x6Hb8e2Nk6UvJFSdyw9NK1scFXJp21gNNYFjVWNgaqyGnkyhtagagCpQb5B7tagJu3HDbjQ8h
    5ypoHjwBb"
  }]
}
          </pre>
        </section>
      </section>

      <section>
        <h2>Proof Representations</h2>

        <p>
This suite relies on detached digital signatures represented using [[MULTIBASE]]
and [[?MULTICODEC]].
        </p>

        <section>
          <h3>DataIntegrityProof</h3>

          <p>
The `verificationMethod` property of the proof MUST be a URL.
Dereferencing the `verificationMethod` MUST result in an object
containing a `type` property with the value set to
`Multikey`.
          </p>

          <p>
The `type` property of the proof MUST be `DataIntegrityProof`.
          </p>
          <p>
The `cryptosuite` property of the proof MUST be `bbs-2023`.
          </p>
          <p>
The `created` property of the proof MUST be an [[XMLSCHEMA11-2]]
formatted date string.
          </p>
          <p>
The `proofPurpose` property of the proof MUST be a string, and MUST
match the verification relationship expressed by the verification method
`controller`.
          </p>
          <p>
The value of the `proofValue` property of the proof MUST be an BBS signature or
BBS proof produced according to [[CFRG-BBS-SIGNATURE]] then serialized and encoded
according to procedures in section <a href="#algorithms"></a>.
          </p>
        </section>
      </section>

    </section>

    <section>
      <h2>Algorithms</h2>

      <p>
The following algorithms describe how to use verifiable credentials with
the BBS Signature Scheme [[CFRG-BBS-SIGNATURE]]. When using the BBS signature
scheme the SHAKE-256 variant SHOULD be used.
      </p>

      <p>
Implementations SHOULD fetch and cache <a>verification method</a> information as
early as possible when adding or verifying proofs. Parameters passed to
functions in this section use information from the <a>verification
method</a> ‚Äî such as the public key size ‚Äî to determine function parameters ‚Äî such
as the cryptographic hashing algorithm.
      </p>

      <p class="advisement">
When the RDF Dataset Canonicalization Algorithm [[RDF-CANON]] is used,
implementations of that algorithm will detect
<a data-cite="RDF-CANON#dataset-poisoning">dataset poisoning</a>
by default, and abort processing upon detection.
      </p>

      <section>
        <h3>Selective Disclosure Functions</h3>

        <section>
          <h4>createShuffledIdLabelMapFunction</h4>
          <p>
The following algorithm creates a label map factory function that uses an
HMAC to shuffle canonical blank node identifiers. The required input is an HMAC
(previously initialized with a secret key), <var>HMAC</var>. A function,
<em>labelMapFactoryFunction</em>, is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Create a function, <var>labelMapFactoryFunction</var>, with one required input
(a canonical node identifier map, <var>canonicalIdMap</var>), that will
return a blank node identifier map, <em>bnodeIdMap</em>, as output. Set the
function's implementation to:
              <ol class="algorithm">
                <li>
Generate a new empty bnode identifier map, <em>bnodeIdMap</em>.
                </li>
                <li>
For each map entry, <em>entry</em>, in <var>canonicalIdMap</var>:
                  <ol class="algorithm">
                    <li>
Perform an HMAC operation on the canonical identifier from the value in <em>entry</em> to get an HMAC
digest, <em>digest</em>.
                    </li>
                    <li>
Generate a new string value, <em>b64urlDigest</em>, and initialize it to "u"
followed by appending a base64url-no-pad encoded version of the <em>digest</em>
value.
                    </li>
                    <li>
Add a new entry, <var>newEntry</var>, to <em>bnodeIdMap</em> using the key
from <em>entry</em> and <em>b64urlDigest</em> as the value.
                    </li>
                  </ol>
                </li>
                <li>
Derive the shuffled mapping from the `bnodeIdMap` as follows:
                  <ol class="algorithm">
                    <li>
Set `hmacIds` to be the sorted array of values from the `bnodeIdMap`, and set
`bnodeKeys` to be the ordered array of keys from the `bnodeIdMap`.
                    </li>
                    <li>
For each key in `bnodeKeys`, replace the `bnodeIdMap` value for that key with the
index position of the value in the `hmacIds` array prefixed by "b", i.e.,
`bnodeIdMap.set(bkey, 'b' + hmacIds.indexOf(bnodeIdMap.get(bkey)))`.
                    </li>
                  </ol>
                </li>
                <li>
Return <em>bnodeIdMap</em>.
                </li>
              </ol>
            </li>
            <li>
Return <var>labelMapFactoryFunction</var>.
            </li>
          </ol>

        </section>


      </section>

      <section>
        <h3>bbs-2023 Functions</h3>
        <section>
          <h4>serializeBaseProofValue</h4>
          <p>
The following algorithm serializes the base proof value, including the
BBS signature, HMAC key, and mandatory pointers.
The required inputs are a base signature <var>bbsSignature</var>,
an HMAC key <var>hmacKey</var>, and an array of
<var>mandatoryPointers</var>.
A single <em>base proof</em> string value is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Initialize a byte array, `proofValue`, that starts with the BBS base proof
header bytes `0xd9`, `0x5d`, and `0x02`.
            </li>
            <li>
Initialize `components` to an array with five elements containing the values of:
`bbsSignature`, `hmacKey`, and `mandatoryPointers`.
            </li>
            <li>
CBOR-encode `components` and append it to `proofValue`.
            </li>
            <li>
Initialize `baseProof` to a string with the multibase-base64url-no-pad-encoding
of `proofValue`. That is, return a string starting with "`u`" and ending with the
base64url-no-pad-encoded value of `proofValue`.
            </li>
            <li>
Return `baseProof` as <em>base proof</em>.
            </li>
          </ol>

        </section>

        <section>
          <h4>parseBaseProofValue</h4>
          <p>
The following algorithm parses the components of a `bbs-2023` selective
disclosure base proof value. The required input is a proof value
(<var>proofValue</var>). A single object, <em>parsed base proof</em>, containing
three elements, using the names "bbsSignature", "hmacKey",
and "mandatoryPointers", is produced  as output.
          </p>

          <ol class="algorithm">
            <li>
Ensure the `proofValue` string starts with `u`, indicating that it is a
multibase-base64url-no-pad-encoded value, and throw an error if it does not.
            </li>
            <li>
Initialize `decodedProofValue` to the result of base64url-no-pad-decoding the
substring following the leading `u` in `proofValue`.
            </li>
            <li>
Ensure that the `decodedProofValue` starts with the BBS base proof header
bytes `0xd9`, `0x5d`, and `0x02`, and throw an error if it does not.
            </li>
            <li>
Initialize `components` to an array that is the result of CBOR-decoding the
bytes that follow the three-byte ECDSA-SD base proof header. Ensure the result
is an array of three elements.
            </li>
            <li>
Return an object with properties set to the three elements, using the names
"bbsSignature", "hmacKey", and "mandatoryPointers",
respectively.
            </li>
          </ol>

        </section>

        <section>
          <h4>createDisclosureData</h4>

          <p>
The following algorithm creates data to be used to generate a derived proof. The
inputs include a JSON-LD document (<var>document</var>), a BBS base proof
(<var>proof</var>), an array of JSON pointers to use to selectively disclose
statements (<var>selectivePointers</var>), and any custom JSON-LD API options
(such as a document loader). A single object, <em>disclosure data</em>, is
produced as output, which contains the "bbsProof", "labelMap",
"mandatoryIndexes", "selectiveIndexes", and "revealDocument" fields.
          </p>

          <ol class="algorithm">
            <li>
Initialize `bbsSignature`, `hmacKey`,  and
`mandatoryPointers` to the values of the associated properties in the object
returned when calling the algorithm in Section
<a href="#parsebaseproofvalue"></a>, passing the `proofValue` from `proof`.
            </li>
            <li>
Initialize `hmac` to an HMAC API using `hmacKey`. The HMAC uses the same hash
algorithm used in the signature algorithm, i.e., SHAKE-256.
            </li>
            <li>
Initialize `labelMapFactoryFunction` to the result of calling the
`createShuffledIdLabelMapFunction` algorithm passing `hmac` as `HMAC`.
            </li>
            <li>
Initialize `combinedPointers` to the concatenation of `mandatoryPointers`
and `selectivePointers`.
            </li>
            <li>
Initialize `groupDefinitions` to a map with the following entries: key of
the string `"mandatory"` and value of `mandatoryPointers`; key of the string
`"selective"` and value of `selectivePointers`; and key of the string `"combined"`
and value of `combinedPointers`.
            </li>
            <li>
Initialize `groups` and `labelMap` to the result of calling the algorithm in
<a href="https://www.w3.org/TR/vc-di-ecdsa/#canonicalizeandgroup">Section 3.3.16
canonicalizeAndGroup</a> of the [[DI-ECDSA]] specification, passing `document`
`labelMapFactoryFunction`,
`groupDefinitions`, and any custom JSON-LD
API options. Note: This step transforms the document into an array of canonical
N-Quads whose order has been shuffled based on 'hmac' applied blank node
identifiers, and groups
the N-Quad strings according to selections based on JSON pointers.
            </li>

            <li>
Compute the mandatory indexes relative to their positions in the combined
statement list, i.e., find the position at which a mandatory statement occurs
in the list of combined statements. One method for doing this is given below.
              <ol class="algorithm">
                <li>
Initialize `mandatoryIndexes` to an empty array. Set `mandatoryMatch` to
`groups.mandatory.matching` map; set `combinedMatch` to
`groups.combined.matching`; and set `combinedIndexes` to the ordered array of
just the keys of the `combinedMatch` map.
                </li>
                <li>
For each key in the `mandatoryMatch` map, find its index in the `combinedIndexes`
array (e.g., `combinedIndexes.indexOf(key)`), and add this value to the
`mandatoryIndexes` array.
                </li>
              </ol>
            </li>
            <li>
Compute the selective indexes relative to their positions in the non-mandatory
statement list, i.e., find the position at which a selected statement occurs in
the list of non-mandatory statements. One method for doing this is given below.
              <ol class="algorithm">
                <li>
Initialize `selectiveIndexes` to an empty array. Set `selectiveMatch` to the
`groups.selective.matching` map; set `mandatoryNonMatch` to the map
`groups.mandatory.nonMatching`; and `nonMandatoryIndexes` to to the ordered array of
just the keys of the `mandatoryNonMatch` map.
                </li>
                <li>
For each key in the `selectiveMatch` map, find its index in the `nonMandatoryIndexes`
array (e.g., `nonMandatoryIndexes.indexOf(key)`), and add this value to the
`selectiveIndexes` array.
                </li>
              </ol>
            </li>

            <li>
Initialize `bbsMessages` to an array of byte arrays obtained from the
UTF-8 encoding of the the values in the `nonMandatory` array.
            </li>
            <li>
Recompute the `bbsHeader` using the following steps:

              <ol class="algorithm">
                <li>
Initialize `proofHash` to the result of calling the RDF Dataset Canonicalization
algorithm [[RDF-CANON]] on `proof` with the `proofValue` removed and then
cryptographically
hashing the result using the same hash that is used by the signature algorithm,
i.e., SHAKE-256. Note: This step can be performed in parallel;
it only needs to be completed before this algorithm terminates, as the result is
part of the return value.
                </li>
                <li>
Initialize `mandatoryHash` to the result of calling the algorithm in
<a href="https://www.w3.org/TR/vc-di-ecdsa/#hashmandatorynquads">Section 3.3.17
hashMandatoryNQuads</a> of the [[DI-ECDSA]] specification, passing the values
from the map
<var>groups.mandatory.matching</var> and utilizing the SHAKE-256 algorithm.
                </li>
                <li>
Set  `bbsHeader` to the concatenation of `proofHash` and `mandatoryHash` in that
order.
                </li>
              </ol>
            </li>

            <li>
Set `bbsProof` to the value computed by the `ProofGen` procedure from
[[CFRG-BBS-SIGNATURE]], i.e. `ProofGen(PK, signature, header, ph, messages, disclosed_indexes)`,
where `PK` is the original issuers public key, `signature` is the
`bbsSignature`, `header` is the `bbsHeader`, `ph` is an empty byte array,
`messages` is `bbsMessages`, and `disclosed_indexes` is `selectiveIndexes`.
            </li>

            <li>
Initialize <var>revealDocument</var> to the result of the "selectJsonLd"
algorithm, passing `document`, and `combinedPointers` as `pointers`.
            </li>
            <li>
Run the RDF Dataset Canonicalization Algorithm [[RDF-CANON]] on
the joined <var>combinedGroup.deskolemizedNQuads</var>, passing any custom
options, and get the canonical bnode identifier map, <var>canonicalIdMap</var>.
Note: This map includes the canonical blank node identifiers that a verifier
will produce when they canonicalize the reveal document.
            </li>
            <li>
Initialize <var>verifierLabelMap</var> to an empty map. This map will map
the canonical blank node identifiers produced by the verifier when they
canonicalize the revealed document, to the blank node identifiers that were
originally signed in the base proof.
            </li>
            <li>
For each key (`inputLabel`) and value (`verifierLabel`) in `canonicalIdMap:
              <ol class="algorithm">
                <li>
Add an entry to `verifierLabelMap`, using `verifierLabel` as the key, and the
value associated with `inputLabel` as a key in `labelMap` as the value.
                </li>
              </ol>
            </li>
            <li>
Return an object with properties matching `bbsProof`, "verifierLabelMap" for `labelMap`,
`mandatoryIndexes`, `selectiveIndexes`, and `revealDocument`.
            </li>
          </ol>

        </section>

        <section>
          <h4>compressLabelMap</h4>
          <p>
The following algorithm compresses a label map. The required input is
label map (<var>labelMap</var>). The output is a <em>compressed label map</em>.
          </p>

          <ol class="algorithm">
            <li>
Initialize `map` to an empty map.
            </li>
            <li>
For each entry (`k`, `v`) in `labelMap`:
              <ol class="algorithm">
                <li>
Add an entry to `map`, with a key that is a base-10 integer parsed from the
characters following the "c14n" prefix in `k`, and a value that is a base-10
integer parsed from the characters following the "b" prefix in `v`.
                </li>
              </ol>
            </li>
            <li>
Return `map` as <em>compressed label map</em>.
            </li>
          </ol>
        </section>

        <section>
          <h4>decompressLabelMap</h4>

          <p>
The following algorithm decompresses a label map. The required input is a
compressed label map (<var>compressedLabelMap</var>). The output is a
<em>decompressed label map</em>.
          </p>

          <ol class="algorithm">
            <li>
Initialize `map` to an empty map.
            </li>
<!--   const key = 'c14n' + k
  const value = 'b' + v -->
            <li>
For each entry (`k`, `v`) in `compressedLabelMap`:
              <ol class="algorithm">
                <li>
Add an entry to `map`, with a key that adds the prefix "c14n" to `k`, and a value
that adds a prefix of "b" to `v`.
                </li>
              </ol>
            </li>
            <li>
Return `map` as <em>decompressed label map</em>.
            </li>
          </ol>

        </section>

        <section>
          <h4>serializeDerivedProofValue</h4>

          <p>
The following algorithm serializes a derived proof value. The required inputs
are a BBS proof (<var>bbsProof</var>),  a label map (<var>labelMap</var>), an
array of mandatory indexes (<var>mandatoryIndexes</var>), and an array of
selective indexes (<var>selectiveIndexes</var>). A single <em>derived proof</em>
value, serialized as a byte string, is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Initialize `compressedLabelMap` to the result of calling the algorithm in
Section <a href="#compresslabelmap"></a>, passing `labelMap` as the parameter.
            </li>
            <li>
Initialize a byte array, `proofValue`, that starts with the BBS disclosure
proof header bytes `0xd9`, `0x5d`, and `0x03`.
            </li>
            <li>
Initialize `components` to an array with four elements containing the values of
`bbsProof`, `compressedLabelMap`, `mandatoryIndexes`, and `selectiveIndexes`.
            </li>
            <li>
CBOR-encode `components` and append it to `proofValue`.
            </li>
            <li>
Return the <em>derived proof</em> as a string with the
multibase-base64url-no-pad-encoding of `proofValue`. That is, return a string
starting with "`u`" and ending with the base64url-no-pad-encoded value of
`proofValue`.
            </li>
          </ol>

        </section>

        <section>
          <h4>parseDerivedProofValue</h4>

          <p>
The following algorithm parses the components of the derived proof value.
The required input is a derived proof value (<var>proofValue</var>). A
A single <em>derived proof value</em> value object is produced as output, which
contains a set of five elements, using the names "bbsProof", "labelMap",
"mandatoryIndexes", and "selectiveIndexes".
          </p>

          <ol class="algorithm">
            <li>
Ensure the `proofValue` string starts with `u`, indicating that it is a
multibase-base64url-no-pad-encoded value, and throw an error if it does not.
            </li>
            <li>
Initialize `decodedProofValue` to the result of base64url-no-pad-decoding the
substring that follows the leading `u` in `proofValue`.
            </li>
            <li>
Ensure that the `decodedProofValue` starts with the ECDSA-SD disclosure proof
header bytes `0xd9`, `0x5d`, and `0x03`, and throw an error if it does not.
            </li>
<!-- [bbsProof, labelMapCompressed, mandatoryIndexes, adjSelectedIndexes] -->
            <li>
Initialize `components` to an array that is the result of CBOR-decoding the
bytes that follow the three-byte BBS disclosure proof header. Ensure the result
is an array of four elements ‚Äî
a byte array, a map of integers to integers, an
array of integers, and another array of integers; otherwise, throw an error.
            </li>
            <li>
Replace the second element in `components` using the result of calling the
algorithm in Section <a href="#decompresslabelmap"></a>, passing the existing
second element of `components` as `compressedLabelMap`.
            </li>
            <li>
Return <em>derived proof value</em> as an object with properties set to the five
elements, using the names "`bbsProof`", "`labelMap`", "`mandatoryIndexes`", and
"`selectiveIndexes`" respectively.
            </li>
          </ol>

        </section>

        <section>
          <h4>createVerifyData</h4>

          <p>
The following algorithm creates the data needed to perform verification of a
BBS-protected <a>verifiable credential</a>. The inputs include a JSON-LD
document (<var>document</var>), a BBS disclosure proof (<var>proof</var>),
and any custom JSON-LD API options (such as a document loader). A single
<em>verify data</em> object value is produced as output containing the following
fields: "`bbsProof`", "`proofHash`", "`mandatoryHash`", "`selectedIndexes`", and
"`nonMandatory`".
          </p>

          <ol class="algorithm">
            <li>
Initialize `proofHash` to the result of performing RDF Dataset Canonicalization
[[RDF-CANON]] on the proof options, i.e., the proof  portion of the document
with the `proofValue` removed. The hash used is the same as that used in
the signature algorithm, i.e., SHA-256 for a P-256 curve. Note: This step can be
performed in parallel; it only needs to be completed before this algorithm needs
to use the `proofHash` value.
            </li>
            <li>
Initialize `bbsProof`, `labelMap`, `mandatoryIndexes`, and `selectiveIndexes` to
the values associated with their property names in the object returned when
calling the algorithm in Section
<a href="#parsederivedproofvalue"></a>, passing `proofValue` from `proof`.
            </li>
            <li>
Initialize `labelMapFactoryFunction` to the result of calling the
"`createLabelMapFunction`" algorithm.
            </li>
            <li>
Initialize `nquads` to the result of calling the "`labelReplacementCanonicalize`"
algorithm of [[DI-ECDSA]], passing `document`, `labelMapFactoryFunction`, and
any custom
JSON-LD API options. Note: This step transforms the document into an array of
canonical N-Quads with pseudorandom blank node identifiers based on `labelMap`.
            </li>
            <li>
Initialize `mandatory` to an empty array.
            </li>
            <li>
Initialize `nonMandatory` to an empty array.
            </li>
            <li>
For each entry (`index`, `nq`) in `nquads`, separate the N-Quads into mandatory
and non-mandatory categories:
              <ol class="algorithm">
                <li>
If `mandatoryIndexes` includes `index`, add `nq` to `mandatory`.
                </li>
                <li>
Otherwise, add `nq` to `nonMandatory`.
                </li>
              </ol>
            </li>
            <li>
Initialize `mandatoryHash` to the result of calling the "`hashMandatory`"
primitive, passing `mandatory`.
            </li>
            <li>
Return an object with properties matching `baseSignature`, `proofHash`,
`nonMandatory`, `mandatoryHash`, and `selectiveIndexes`.
            </li>
          </ol>

        </section>

      </section>

      <section>
        <h3>bbs-2023</h3>

        <p>
The `bbs-2023` cryptographic suite takes an input document, canonicalizes
the document using the Universal RDF Dataset Canonicalization Algorithm
[[RDF-CANON]], and then applies a number of transformations and cryptographic
operations resulting in the production of a data integrity proof. The algorithms
in this section also include the verification of such a data integrity proof.
        </p>

        <section>
          <h4>Add Base Proof (bbs-2023)</h4>

          <p>
To generate a base proof, the algorithm in
<a href="https://www.w3.org/TR/vc-data-integrity/#add-proof">
Section 4.1: Add Proof</a> of the Data Integrity
[[VC-DATA-INTEGRITY]] specification MUST be executed.
For that algorithm, the cryptographic suite specific
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-transformation-algorithm">
transformation algorithm</a> is defined in Section
<a href="#base-proof-transformation-bbs-2023"></a>, the
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-hashing-algorithm">
hashing algorithm</a> is defined in Section <a href="#base-proof-hashing-bbs-2023"></a>,
and the
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-proof-serialization-algorithm">
proof serialization algorithm</a> is defined in Section
<a href="#base-proof-serialization-bbs-2023"></a>.
          </p>
        </section>

        <section>
          <h4>Base Proof Transformation (bbs-2023)</h4>
          <p>
The following algorithm specifies how to transform an unsecured input document
into a transformed document that is ready to be provided as input to the
hashing algorithm in Section <a href="#base-proof-hashing-bbs-2023"></a>.
          </p>
          <p>
Required inputs to this algorithm are an
<a data-cite="vc-data-integrity#dfn-unsecured-data-document">
unsecured data document</a> (<var>unsecuredDocument</var>) and
transformation options (<var>options</var>). The
transformation options MUST contain a type identifier for the
<a data-cite="vc-data-integrity#dfn-cryptosuite">
cryptographic suite</a> (<var>type</var>), a cryptosuite
identifier (<var>cryptosuite</var>), and a verification method
(<var>verificationMethod</var>). The transformation options MUST contain an
array of mandatory JSON pointers (<var>mandatoryPointers</var>) and MAY contain
additional options, such as a JSON-LD document loader. A <em>transformed data
document</em> is produced as output. Whenever this algorithm encodes strings, it
MUST use UTF-8 encoding.
          </p>
          <ol class="algorithm">
            <li>
Initialize `hmac` to an HMAC API using a locally generated and exportable HMAC
key. The HMAC uses the same hash algorithm used in the signature algorithm,
i.e., SHAKE-256.
            </li>
            <li>
Initialize `labelMapFactoryFunction` to the result of calling the
`createShuffledIdLabelMapFunction` algorithm passing `hmac` as `HMAC`.
            </li>
            <li>
Initialize `groupDefinitions` to a map with an entry with a key of the string
"`mandatory`" and a value of <var>mandatoryPointers</var>.
            </li>
            <li>
Initialize `groups` to the result of calling the algorithm in
<a href="https://www.w3.org/TR/vc-di-ecdsa/#canonicalizeandgroup">Section 3.3.16
canonicalizeAndGroup</a> of the [[DI-ECDSA]] specification, passing
`labelMapFactoryFunction`,
`groupDefinitions`, `unsecuredDocument` as `document`, and any custom JSON-LD
API options. Note: This step transforms the document into an array of canonical
N-Quads whose order has been shuffled based on 'hmac' applied blank node
identifiers, and groups
the N-Quad strings according to selections based on JSON pointers.
            </li>
            <li>
Initialize `mandatory` to the values in the `groups.mandatory.matching` map.
            </li>
            <li>
Initialize `nonMandatory` to the values in the `groups.mandatory.nonMatching`
map.
            </li>
            <li>
Initialize `hmacKey` to the result of exporting the HMAC key from `hmac`.
            </li>
            <li>
Return an object with "`mandatoryPointers`" set to `mandatoryPointers`,
"`mandatory`" set to `mandatory`, "`nonMandatory`" set to `nonMandatory`,
and "`hmacKey`" set to `hmacKey`.
            </li>
          </ol>
        </section>

        <section>
          <h4>Base Proof Hashing (bbs-2023)</h4>

          <p>
The following algorithm specifies how to cryptographically hash a
<em>transformed data document</em> and <em>proof configuration</em>
into cryptographic hash data that is ready to be provided as input to the
algorithms in Section <a href="#base-proof-serialization-bbs-2023"></a>.
          </p>

          <p>
The required inputs to this algorithm are a <em>transformed data document</em>
(<var>transformedDocument</var>) and <em>canonical proof configuration</em>
(<var>canonicalProofConfig</var>). A <em>hash data</em> value represented
as an object is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Initialize `proofHash` to the result of calling the RDF Dataset Canonicalization
algorithm [[RDF-CANON]] on `canonicalProofConfig` and then cryptographically
hashing the result using the same hash that is used by the signature algorithm,
i.e., SHAKE-256. Note: This step can be performed in parallel;
it only needs to be completed before this algorithm terminates, as the result is
part of the return value.
            </li>
            <li>
Initialize `mandatoryHash` to the result of calling the the algorithm in
<a href="https://www.w3.org/TR/vc-di-ecdsa/#hashmandatorynquads">Section 3.3.17
hashMandatoryNQuads</a> of the [[DI-ECDSA]] specification, passing
<var>transformedDocument</var>.`mandatory` and utilizing the SHAKE-256
algorithm.
            </li>
            <li>
Initialize `hashData` as a deep copy of <var>transformedDocument</var>, and
add `proofHash` as "`proofHash`" and `mandatoryHash` as "`mandatoryHash`" to that
object.
            </li>
            <li>
Return `hashData` as <em>hash data</em>.
            </li>
          </ol>

        </section>

        <section>
          <h4>Base Proof Configuration (bbs-2023)</h4>

          <p>
The following algorithm specifies how to generate a
<em>proof configuration</em> from a set of <em>proof options</em>
that is used as input to the
<a href="#base-proof-hashing-bbs-2023">base proof hashing algorithm</a>.
          </p>

          <p>
The required inputs to this algorithm are <em>proof options</em>
(<var>options</var>). The <em>proof options</em> MUST contain a type identifier
for the
<a data-cite="vc-data-integrity#dfn-cryptosuite">
cryptographic suite</a> (<var>type</var>) and MUST contain a cryptosuite
identifier (<var>cryptosuite</var>). A <em>proof configuration</em>
object is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Let <var>proofConfig</var> be an empty object.
            </li>
            <li>
Set <var>proofConfig</var>.<var>type</var> to
<var>options</var>.<var>type</var>.
            </li>
            <li>
If <var>options</var>.<var>cryptosuite</var> is set, set
<var>proofConfig</var>.<var>cryptosuite</var> to its value.
            </li>
            <li>
If <var>options</var>.<var>type</var> is not set to `DataIntegrityProof` and
<var>proofConfig</var>.<var>cryptosuite</var> is not set to `bbs-2023`, an
`INVALID_PROOF_CONFIGURATION` error MUST be raised.
            </li>
            <li>
Set <var>proofConfig</var>.<var>created</var> to
<var>options</var>.<var>created</var>. If the value is not a valid
[[XMLSCHEMA11-2]] datetime, an `INVALID_PROOF_DATETIME` error MUST be raised.
            </li>
            <li>
Set <var>proofConfig</var>.<var>verificationMethod</var> to
<var>options</var>.<var>verificationMethod</var>.
            </li>
            <li>
Set <var>proofConfig</var>.<var>proofPurpose</var> to
<var>options</var>.<var>proofPurpose</var>.
            </li>
            <li>
Set <var>proofConfig</var>.<var>@context</var> to
<var>unsecuredDocument</var>.<var>@context</var>.
            </li>
            <li>
Let <var>canonicalProofConfig</var> be the result of applying the
Universal RDF Dataset Canonicalization Algorithm
[[RDF-CANON]] to the <var>proofConfig</var>.
            </li>
            <li>
Return <var>canonicalProofConfig</var>.
            </li>
          </ol>

        </section>


        <section>
          <h4>Base Proof Serialization (bbs-2023)</h4>

          <p>
The following algorithm, to be called by an issuer of a BBS-protected Verifiable
Credential, specifies how to create a base proof. The base proof is to be
given only to the holder, who is responsible for generating a derived proof from
it, exposing only selectively disclosed details in the proof to a verifier. This
algorithm is designed to be used in conjunction with the algorithms defined
in the Data Integrity [[VC-DATA-INTEGRITY]] specification,
<a data-cite="vc-data-integrity#algorithms">
Section 4: Algorithms</a>. Required inputs are
cryptographic hash data (<var>hashData</var>) and
<em>proof options</em> (<var>options</var>). The
<em>proof options</em> MUST contain a type identifier for the
<a data-cite="vc-data-integrity#dfn-cryptosuite">
cryptographic suite</a> (<var>type</var>) and MAY contain a cryptosuite
identifier (<var>cryptosuite</var>). A single <em>digital proof</em> value
represented as series of bytes is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Initialize `proofHash`, `mandatoryPointers`, `mandatoryHash`, `nonMandatory`,
and `hmacKey` to the values associated with their property names in
<var>hashData</var>.
            </li>
            <li>
Initialize `bbsHeader` to the concatenation of `proofHash` and `mandatoryHash` in
that order.
            </li>
            <li>
Initialize `bbsMessages` to an array of byte arrays obtained from the
UTF-8 encoding of the the values in the `nonMandatory` array.
            </li>
            <li>
Compute the `bbsSignature` using the `Sign` procedure of [[CFRG-BBS-Signature]]
with appropriate key material and `bbsHeader` for the `header` and `bbsMessages`
for the `messages`
            </li>
            <li>
Initialize `proofValue to the result of calling the algorithm in Section
<a href="#serializebaseproofvalue"></a>, passing `bbsSignature`,
`hmacKey`, and `mandatoryPointers` as parameters
to the algorithm.
            </li>
            <li>
Return `proofValue` as <em>digital proof</em>.
            </li>
          </ol>
        </section>


        <section>
          <h4>Add Derived Proof (bbs-2023)</h4>

          <p>
The following algorithm, to be called by a holder of a `bbs-2023`-protected
<a>verifiable credential</a>, creates a selective disclosure derived proof.
The derived proof is to be given to the <a>verifier</a>. The inputs include a
JSON-LD document (<var>document</var>), a BBS base proof
(<var>proof</var>), an array of JSON pointers to use to selectively disclose
statements (<var>selectivePointers</var>), and any custom JSON-LD API options,
such as a document loader. A single <em>selectively revealed document</em>
value, represented as an object, is produced as output.
          </p>

          <ol>
            <li>
Initialize `bbsProof`,  `labelMap`, `mandatoryIndexes`, `selectiveIndexes`, and
`revealDocument` to the values associated with their
property names in the object returned when calling the algorithm in
Section <a href="#createdisclosuredata"></a>, passing the `document`, `proof`,
`selectivePointers`, and any custom JSON-LD API options, such as a document
loader.
            </li>
            <li>
Initialize `newProof` to a shallow copy of `proof`.
            </li>
            <li>
Replace `proofValue` in `newProof` with the result of calling the algorithm
in Section <a href="#serializederivedproofvalue"></a>, passing `bbsProof`,
`labelMap`, `mandatoryIndexes`, and `selectiveIndexes`.
            </li>
            <li>
Set the value of the "`proof`" property in `revealDocument` to `newProof`.
            </li>
            <li>
Return `revealDocument` as the <em>selectively revealed document</em>.
            </li>
          </ol>

        </section>


        <section>
          <h4>Verify Derived Proof (bbs-2023)</h4>

          <p>
The following algorithm attempts verification of a `bbs-2023` derived
proof. This algorithm is called by a verifier of an BBS-protected
<a>verifiable credential</a>. The inputs include a JSON-LD document
(<var>document</var>), a BBS disclosure proof (<var>proof</var>), and any
custom JSON-LD API options (such as a document loader). A single boolean
<em>verification result</em> value is produced as output.
          </p>

          <ol class="algorithm">
            <!-- [bbsProof, labelMapCompressed, mandatoryIndexes, adjSelectedIndexes] -->
            <li>
Initialize `bbsProof`, `proofHash`, `mandatoryHash`, `selectedIndexes`, and
`nonMandatory` to the values associated with their property
names in the object returned when calling the algorithm in Section
<a href="#createverifydata"></a>, passing the `document`, `proof`, and any
custom JSON-LD API options (such as a document loader).
            </li>
            <li>
Initialize `bbsHeader` to the concatenation of `proofHash` and `mandatoryHash`
in that order. Initialize `disclosedMessages` to an array of byte arrays
obtained from the UTF-8 encoding of the elements of the `nonMandatory` array.
            </li>
<!-- result = ProofVerify(PK, proof, header, ph, disclosed_messages, disclosed_indexes) -->
            <li>
Initialize `verificationResult` to the result of applying the verification
algorithm `ProofVerify` of [[CFRG-BBS-SIGNATURE]]
with `PK` set as the public key of the original issuer, `proof` set as `bbsProof`,
`header` set as `bbsHeader`, `disclosed_messages` set as `disclosedMessages`,
`ph` set as an empty byte array, and `disclosed_indexes` set as
`selectiveIndexes`. Return `verificationResult` as <em>verification result</em>.
            </li>
          </ol>

        </section>

      </section>

    </section>

    <section>
      <h2>Security Considerations</h2>

      <p class="advisement">
        Before reading this section, readers are urged to familiarize themselves
        with general security advice provided in the
        <a href="https://www.w3.org/TR/vc-data-integrity/#security-considerations">
        Security Considerations section of the Data Integrity specification</a>.
      </p>

      <section class="informative">
        <h3>Base Proof Security Properties</h3>

        <p>
The security of the base proof is dependent on the security properties of the
associated <em>BBS signature</em>. Digital signatures may exhibit a number of
desirable cryptographic properties [[Taming_EdDSAs]] among these are:
        </p>
        <p><strong>EUF-CMA</strong> (<em>existential unforgeability under
chosen message attacks</em>) is usually the minimal security property required
of a signature scheme. It guarantees that any efficient adversary who has the
public key
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
            <mstyle displaystyle="true" scriptlevel="0">
              <mrow data-mjx-texclass="ORD">
                <mtable rowspacing=".5em" columnspacing="1em" displaystyle="true">
                  <mtr>
                    <mtd>
                      <mi>p</mi>
                      <mi>k</mi>
                    </mtd>
                  </mtr>
                </mtable>
              </mrow>
            </mstyle>
          </math>
of the signer and received an arbitrary number of signatures on
messages of its choice (in an adaptive manner):
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
            <mstyle displaystyle="true" scriptlevel="0">
              <mrow data-mjx-texclass="ORD">
                <mtable rowspacing=".5em" columnspacing="1em" displaystyle="true">
                  <mtr>
                    <mtd>
                      <mo fence="false" stretchy="false">{</mo>
                      <msub>
                        <mi>m</mi>
                        <mi>i</mi>
                      </msub>
                      <mo>,</mo>
                      <msub>
                        <mi>&#x3C3;</mi>
                        <mi>i</mi>
                      </msub>
                      <msubsup>
                        <mo fence="false" stretchy="false">}</mo>
                        <mrow data-mjx-texclass="ORD">
                          <mi>i</mi>
                          <mo>=</mo>
                          <mn>1</mn>
                        </mrow>
                        <mi>N</mi>
                      </msubsup>
                    </mtd>
                  </mtr>
                </mtable>
              </mrow>
            </mstyle>
          </math>,
cannot output a valid signature
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
            <mstyle displaystyle="true" scriptlevel="0">
              <mrow data-mjx-texclass="ORD">
                <mtable rowspacing=".5em" columnspacing="1em" displaystyle="true">
                  <mtr>
                    <mtd>
                      <msup>
                        <mi>&#x3C3;</mi>
                        <mo>&#x2217;</mo>
                      </msup>
                    </mtd>
                  </mtr>
                </mtable>
              </mrow>
            </mstyle>
          </math>
for a new message
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
            <mstyle displaystyle="true" scriptlevel="0">
              <mrow data-mjx-texclass="ORD">
                <mtable rowspacing=".5em" columnspacing="1em" displaystyle="true">
                  <mtr>
                    <mtd>
                      <msup>
                        <mi>m</mi>
                        <mo>&#x2217;</mo>
                      </msup>
                      <mo>&#x2209;</mo>
                      <mo fence="false" stretchy="false">{</mo>
                      <msub>
                        <mi>m</mi>
                        <mi>i</mi>
                      </msub>
                      <msubsup>
                        <mo fence="false" stretchy="false">}</mo>
                        <mrow data-mjx-texclass="ORD">
                          <mi>i</mi>
                          <mo>=</mo>
                          <mn>1</mn>
                        </mrow>
                        <mi>N</mi>
                      </msubsup>
                    </mtd>
                  </mtr>
                </mtable>
              </mrow>
            </mstyle>
          </math>
(except with negligible probability). In case the attacker outputs a valid
signature on a new message:
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
            <mstyle displaystyle="true" scriptlevel="0">
              <mrow data-mjx-texclass="ORD">
                <mtable rowspacing=".5em" columnspacing="1em" displaystyle="true">
                  <mtr>
                    <mtd>
                      <mo stretchy="false">(</mo>
                      <msup>
                        <mi>m</mi>
                        <mo>&#x2217;</mo>
                      </msup>
                      <mo>,</mo>
                      <msup>
                        <mi>&#x3C3;</mi>
                        <mo>&#x2217;</mo>
                      </msup>
                      <mo stretchy="false">)</mo>
                    </mtd>
                  </mtr>
                </mtable>
              </mrow>
            </mstyle>
          </math>,
it is called an <em>existential forgery</em>.
        </p>
        <p><strong>SUF-CMA</strong> (<em>strong unforgeability under chosen
message attacks</em>) is a stronger notion than <em>EUF-CMA</em>. It guarantees
that for any efficient adversary who has the public key
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
            <mstyle displaystyle="true" scriptlevel="0">
              <mrow data-mjx-texclass="ORD">
                <mtable rowspacing=".5em" columnspacing="1em" displaystyle="true">
                  <mtr>
                    <mtd>
                      <mi>p</mi>
                      <mi>k</mi>
                    </mtd>
                  </mtr>
                </mtable>
              </mrow>
            </mstyle>
          </math>
of the signer and received an arbitrary number of signatures on messages of its
choice:
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
            <mstyle displaystyle="true" scriptlevel="0">
              <mrow data-mjx-texclass="ORD">
                <mtable rowspacing=".5em" columnspacing="1em" displaystyle="true">
                  <mtr>
                    <mtd>
                      <mo fence="false" stretchy="false">{</mo>
                      <msub>
                        <mi>m</mi>
                        <mi>i</mi>
                      </msub>
                      <mo>,</mo>
                      <msub>
                        <mi>&#x3C3;</mi>
                        <mi>i</mi>
                      </msub>
                      <msubsup>
                        <mo fence="false" stretchy="false">}</mo>
                        <mrow data-mjx-texclass="ORD">
                          <mi>i</mi>
                          <mo>=</mo>
                          <mn>1</mn>
                        </mrow>
                        <mi>N</mi>
                      </msubsup>
                    </mtd>
                  </mtr>
                </mtable>
              </mrow>
            </mstyle>
          </math>,
it cannot output a new valid signature pair
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
            <mstyle displaystyle="true" scriptlevel="0">
              <mrow data-mjx-texclass="ORD">
                <mtable rowspacing=".5em" columnspacing="1em" displaystyle="true">
                  <mtr>
                    <mtd>
                      <mo stretchy="false">(</mo>
                      <msup>
                        <mi>m</mi>
                        <mo>&#x2217;</mo>
                      </msup>
                      <mo>,</mo>
                      <msup>
                        <mi>&#x3C3;</mi>
                        <mo>&#x2217;</mo>
                      </msup>
                      <mo stretchy="false">)</mo>
                    </mtd>
                  </mtr>
                </mtable>
              </mrow>
            </mstyle>
          </math>,
such that
          <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
            <mstyle displaystyle="true" scriptlevel="0">
              <mrow data-mjx-texclass="ORD">
                <mtable rowspacing=".5em" columnspacing="1em" displaystyle="true">
                  <mtr>
                    <mtd>
                      <mo stretchy="false">(</mo>
                      <msup>
                        <mi>m</mi>
                        <mo>&#x2217;</mo>
                      </msup>
                      <mo>,</mo>
                      <msup>
                        <mi>&#x3C3;</mi>
                        <mo>&#x2217;</mo>
                      </msup>
                      <mo stretchy="false">)</mo>
                      <mo>&#x2209;</mo>
                      <mo fence="false" stretchy="false">{</mo>
                      <msup>
                        <mi>m</mi>
                        <mi>i</mi>
                      </msup>
                      <mo>,</mo>
                      <msup>
                        <mi>&#x3C3;</mi>
                        <mi>i</mi>
                      </msup>
                      <msubsup>
                        <mo fence="false" stretchy="false">}</mo>
                        <mrow data-mjx-texclass="ORD">
                          <mi>i</mi>
                          <mo>=</mo>
                          <mn>1</mn>
                        </mrow>
                        <mi>N</mi>
                      </msubsup>
                    </mtd>
                  </mtr>
                </mtable>
              </mrow>
            </mstyle>
          </math>
(except with negligible probability). Strong unforgeability implies that an
adversary cannot only sign new messages, but also cannot find a new signature
on an old message.
        </p>

        <p>
In [[CDL2016]] under some reasonable assumptions BBS signatures were proven to
be EUF-CMA. Furthermore, in [[TZ2023]], under similar assumptions BBS signatures
were proven to be SUF-CMA. In both cases the assumptions are related to the
hardness of the discrete logarithm problem which is not considered post large
scale quantum computing secure.
        </p>
        <p>
Under non-quantum computing conditions [[CFRG-BBS-SIGNATURE]] provides
additional security guidelines to BBS signature suite implementors. Further
security considerations related to pairing friendly curves are discussed in
[[CFRG-PAIRING-FRIENDLY]].
        </p>
      </section>

      <section class="informative">
        <h3>Derived Proof Security Properties</h3>
        <p>
The security of the derived proof is dependent on the security properties of
the associated <em>BBS proof</em>. Both [[CDL2016]] and [[TZ2023]] prove that a
<em>BBS proof</em> is <q>a zero knowledge proof of knowledge of a BBS
  signature</q>.
        </p>
        <p>
As explained in [[CFRG-BBS-SIGNATURE]] this means:
        </p>
        <blockquote>
a verifying party in receipt of a proof is unable to determine which signature
was used to generate the proof, removing a common source of correlation. In
general, each proof generated is indistinguishable from random even for two
proofs generated from the same signature.
        </blockquote>
        <p>
and
        </p>
        <blockquote>
The proofs generated by the scheme prove to a verifier that the party who
generated the proof (holder/prover) was in possession of a signature without
revealing it.
        </blockquote>
        <p>
More precisely, verification of a <em>BBS proof</em> requires the original
issuers public key as well as the unaltered, revealed <em>BBS message</em> in
the proper order.
        </p>
      </section>

    </section>

    <section>
      <h2>Privacy Considerations</h2>
      <p class="issue">TODO: We need to add a complete list of privacy
      considerations.</p>
    </section>

    <section class="appendix informative">
      <h2>Test Vectors</h2>
      <p>
Demonstration of selective disclosure features including mandatory disclosure,
selective disclosure, and overlap between those,
requires an input credential document with more content than previous test
vectors. To avoid excessively long test vectors, the starting document test
vector is based on a purely fictitious windsurfing (sailing) competition
scenario. In addition, we break the test vectors into two groups, based on those
that would be generated by the issuer (base proof) and those that would be
generated by the holder (derived proof).
        </p>
        <section>
          <h4>Base Proof</h4>
          <p>
To add a selective disclosure base proof to a document, the issuer needs
the following cryptographic key material:
          </p>
          <ol>
            <li>
The issuer's private/public key pair, i.e., the key pair corresponding to the
verification method that will be part of the proof.
            </li>
            <li>
An HMAC key. This is used to randomize the order of the blank node IDs to avoid
potential information leakage via the blank node ID ordering. This is used only
once, and is shared between issuer and holder. The HMAC in this case is
functioning as a pseudorandom function (PRF).
            </li>
          </ol>
          <p>
The key material used for generating the test vectors to test <i>add base
proof</i> is shown below. Hexadecimal representation is used for the BBS key
pairs and the HMAC key.
          </p>
          <pre class="example nohighlight" title="Private and Public keys for Signature"
          data-include="TestVectors/BBSKeyMaterial.json"
          data-include-format="text">
          </pre>
          <p>
In our scenario, a sailor is registering with a race organizer for a series of
windsurfing races to be held over a number of days on Maui. The organizer will
inspect the sailor's equipment to certify that what has been declared is
accurate. The sailor's unsigned equipment inventory is shown below.
          </p>
          <pre class="example nohighlight" title="Credential without Proof" data-include="TestVectors/windDoc.json"
          data-include-format="text"></pre>
          <p>
In addition to letting other sailors know what kinds of equipment their competitors
may be sailing on, it is mandatory that each sailor disclose the year of their
most recent windsurfing board and full details on two of their sails. Note that
all sailors are identified by a sail number that is printed on all their
equipment. This mandatory information is specified via an array of JSON pointers
as shown below.
          </p>
          <pre class="example nohighlight" title="Mandatory Pointers" data-include="TestVectors/windMandatory.json"
          data-include-format="text"></pre>
          <p>
The result of applying the above JSON pointers to the sailor's equipment document
is shown below.
          </p>
          <pre class="example nohighlight" title="JSON Pointers and Values" data-include="TestVectors/addPointerValues.json"
          data-include-format="text"></pre>
          <p>
Transformation of the unsigned document begins with canonicalizing the document,
as shown below.
          </p>
          <pre class="example nohighlight" title="Canonical Document" data-include="TestVectors/addBaseDocCanon.json"
          data-include-format="text"></pre>
          <p>
To prevent possible information leakage from the ordering of the blank node IDs
these are processed through a PRF (i.e., the HMAC) to give the canonicalized HMAC
document shown below. This represents an ordered list of statements that will be
subject to mandatory and selective disclosure, i.e., it is from this list that
statements are grouped.
          </p>
          <pre class="example nohighlight" title="Canonical HMAC Document" data-include="TestVectors/addBaseDocHMACCanon.json"
          data-include-format="text"></pre>
          <p>
The above canonical document gets grouped into mandatory and non-mandatory
statements. The final output of the selective disclosure transformation process
is shown below. Each statement is now grouped as mandatory or non-mandatory, and
its index in the previous list of statements is remembered.
          </p>
          <pre class="example nohighlight" title="Add Base Transformation" data-include="TestVectors/addBaseTransform.json"
          data-include-format="text"></pre>
          <p>
The next step is to create the base proof configuration and canonicalize it.
This is shown in the following two examples.
          </p>
          <pre class="example nohighlight" title="Base Proof Configuration" data-include="TestVectors/addProofConfig.json"
          data-include-format="text"></pre>
          <pre class="example nohighlight" title="Canonical Base Proof Configuration" data-include="TestVectors/addProofConfigCanon.txt"
          data-include-format="text"></pre>
          <p>
In the hashing step, we compute the SHAKE-256 hash of the canonicalized proof
options to produce the `proofHash`, and we compute the SHAKE-256 hash of the
join of all the mandatory N-Quads to produce the `mandatoryHash`. These are
shown below in hexadecimal format.
          </p>
          <pre class="example nohighlight" title="Add Base Hashes" data-include="TestVectors/addHashData.json"
          data-include-format="text"></pre>
          <p>
Shown below are the computed `bbsSignature` in hexadecimal, and the
`mandatoryPointers`. These are are fed to the final serialization step with the
`hmacKey`.
          </p>
          <pre class="example nohighlight" title="Add Base Signing" data-include="TestVectors/addRawBaseSignatureInfo.json"
          data-include-format="text"></pre>
          <p>
Finally, the values above are run through the algorithm of Section
<a href="#serializebaseproofvalue"></a>, to produce the `proofValue` which is
used in the signed base document shown below.
          </p>
          <pre class="example nohighlight" title="Signed Base Document" data-include="TestVectors/addSignedSDBase.json"
          data-include-format="text"></pre>
        </section>
        <section>
          <h4>Derived Proof</h4>
          <p>
To create a derived proof, a holder starts with a signed document
containing a base proof. The base document we will use for these test vectors is
the final example from Section <a href="#base-proof"></a>, above. The first
step is to run the algorithm of Section <a href="#parsebaseproofvalue"></a> to
recover `bbsSignature`, `hmacKey`, and `mandatoryPointers`, as shown below.
          </p>
          <pre class="example nohighlight" title="Recovered Base Signature Data" data-include="TestVectors/derivedRecoveredBaseData.json"
          data-include-format="text"></pre>
          <p>
Next, the holder needs to indicate what else, if anything, they wish to reveal
to the verifiers, by specifying JSON pointers for selective disclosure. In our
windsurfing competition scenario, a sailor (the holder) has just completed their
first day of racing, and wishes to reveal to the general public (the verifiers)
all the details of the windsurfing boards they used in the competition. These
are shown below. Note that this slightly overlaps with the mandatory disclosed
information which included only the year of their most recent board.
          </p>
          <pre class="example nohighlight" title="Selective Disclosure Pointers" data-include="TestVectors/windSelective.json"
          data-include-format="text"></pre>
          <p>
To produce the `revealDocument` (i.e., the unsigned document that will
eventually be signed and sent to the verifier), we append the selective pointers
to the mandatory pointers, and input these combined pointers along with the
document without proof to the `selectJsonLd` algorithm of [[DI-ECDSA]],
to get the result shown below.
          </p>
          <pre class="example nohighlight" title="Unsigned Reveal Document" data-include="TestVectors/derivedUnsignedReveal.json"
          data-include-format="text"></pre>
          <p>
Now that we know what the revealed document looks like, we need to furnish
appropriately updated information to the verifier about which statements are
mandatory, and the indexes for the selected non-mandatory statements. Running
step 6 of the
<a href="#createdisclosuredata"></a> yields an abundance of information about
various statement groups relative to the original document. Below we show a
portion of the indexes for those groups.
          </p>
          <pre class="example nohighlight" title="Derived Group Indexes" data-include="TestVectors/derivedGroupIndexes.json"
          data-include-format="text"></pre>
          <p>
The verifier needs to be able to aggregate and hash the mandatory statements. To
enable this, we furnish them with a list of indexes of the mandatory statements
adjusted to their positions in the reveal document (i.e., relative to the
`combinedIndexes`), while the `selectiveIndexes` need to be adjusted relative to
their positions within the `nonMandatoryIndexes`. These "adjusted" indexes are
shown below.
          </p>
          <pre class="example nohighlight" title="Adjusted Mandatory and Selective Indexes" data-include="TestVectors/derivedAdjIndexes.json"
          data-include-format="text"></pre>

          <p>
The last important piece of disclosure data is a mapping of canonical blank node
IDs to HMAC-based shuffled IDs, the `labelMap`, computed according to Section
<a href="#createdisclosuredata"></a>. This is shown below along with
the rest of the disclosure data minus the reveal document.
          </p>
          <pre class="example nohighlight" title="Disclosure Data" data-include="TestVectors/derivedDisclosureData.json"
          data-include-format="text"></pre>
          <p>
Finally, using the disclosure data above with the algorithm of Section
<a href="#serializederivedproofvalue"></a>, we obtain the signed derived (reveal)
document shown below.
          </p>
          <pre class="example nohighlight" title="Signed Derived Document" data-include="TestVectors/derivedRevealDocument.json"
          data-include-format="text"></pre>
        </section>

    </section>
    <section class="appendix">
      <h2>Acknowledgements</h2>
      <p>
        Portions of the work on this specification have been funded by the
        United States Department of Homeland Security's (US DHS) Silicon Valley
        Innovation Program under contracts
        70RSAT20T00000003,
        and
        70RSAT20T00000033.
        The content of this specification does not
        necessarily reflect the position or the policy of the U.S. Government
        and no official endorsement should be inferred.
      </p>
    </section>
  </body>
</html>
