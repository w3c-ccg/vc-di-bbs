<!DOCTYPE html>
<html>
  <head>
    <title>BBS Cryptosuite v2023</title>
    <meta http-equiv='Content-Type' content='text/html;charset=utf-8'/>
    <!--
      === NOTA BENE ===
      For the three scripts below, if your spec resides on dev.w3 you can check them
      out in the same tree and use relative links so that they'll work offline,
     -->
    <script src='https://www.w3.org/Tools/respec/respec-w3c' class='remove'></script>
    <script class='remove' src="https://w3c.github.io/vc-data-integrity/common.js"></script>

    <script type="text/javascript" class="remove">
      const respecConfig = {
        // specification status (e.g. WD, LCWD, NOTE, etc.). If in doubt use ED.
        specStatus:           "ED",

        // the specification's short name, as in http://www.w3.org/TR/short-name/
        shortName: "vc-di-bbs",
        subtitle: "Securing Verifiable Credentials with Selective Disclosure using BBS Signatures",
        group: "vc",
        // latestVersion: "https://www.w3.org/community/reports/credentials/CG-FINAL-vc-di-bbs-20230405/",

        // if you wish the publication date to be other than today, set this
        // publishDate:  "2023-05-18",

        // if there is a previously published draft, uncomment this and set its YYYY-MM-DD date
        // and its maturity status
        // previousPublishDate:  "1977-03-15",
        // previousMaturity:  "WD",

        // if there a publicly available Editor's Draft, this is the link
        edDraftURI:           "https://w3c.github.io/vc-di-bbs/",

        // if this is a LCWD, uncomment and set the end of its review period
        // lcEnd: "2009-08-05",

        // if you want to have extra CSS, append them to this list
        // it is recommended that the respec.css stylesheet be kept
        //extraCSS:             ["spec.css", "prettify.css"],

        // editors, add as many as you like
        // only "name" is required
        editors:  [{
            name: "Tobias Looker", url: "https://mattr.global/",
            company: "Mattr", companyURL: "https://mattr.global/", w3cid: 109171,
          }, {
            name: "Greg Bernstein", url: "https://www.grotto-networking.com/",
            company: "Invited Expert", w3cid: 140479
          }, {
            name: "Manu Sporny", url: "https://digitalbazaar.com/",
            company: "Digital Bazaar", companyURL: "https://digitalbazaar.com/",
            w3cid: 41758
          }
        ],

        // extend the bibliography entries
        //localBiblio: webpayments.localBiblio,

        // wg:           "Verifiable Credentials Working Group Group",
        // URI of the public WG page
        // wgURI:        "https://www.w3.org/community/credentials/",
        // name (with the @w3c.org) of the public mailing to which comments are due
        // wgPublicList: "public-credentials",
        // URI of the patent status for this WG, for Rec-track documents
        // !!!! IMPORTANT !!!!
        // This is important for Rec-track documents, do not copy a patent URI from a random
        // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
        // Team Contact.
        // wgPatentURI:  "https://www.w3.org/community/about/agreements/cla/",

        github: "https://github.com/w3c/vc-di-bbs",

        // URI of the patent status for this WG, for Rec-track documents
        // !!!! IMPORTANT !!!!
        // This is important for Rec-track documents, do not copy a patent URI from a random
        // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
        // Team Contact.
        // wgPatentURI:  "",
        maxTocLevel: 4,
        /*preProcess: [ webpayments.preProcess ],
        alternateFormats: [ {uri: "diff-20111214.html", label: "diff to previous version"} ],
        */
        localBiblio:  {
          "RDF-DATASET-NORMALIZATION": {
            title:    "RDF Dataset Normalization 1.0",
            href:     "http://json-ld.github.io/normalization/spec/",
            authors:  ["David Longley", "Manu Sporny"],
            status:   "CGDRAFT",
            publisher:  "JSON-LD Community Group"
          },
          "RDF-CONCEPTS": {
            title:    "RDF 1.1 Concepts and Abstract Syntax",
            href:     "https://www.w3.org/TR/rdf11-concepts/",
            authors:  ["Richard Cyganiak", "David Wood", "Markus Lanthaler"],
            status:   "Recommendation",
            publisher:  "W3C"
          },
          "RDF-N-Quads": {
            title:    "RDF 1.1 N-Quads",
            href:     "http://json-ld.github.io/normalization/spec/",
            authors:  ["Gaven Carothers"],
            status:   "Recommendation",
          },
          "VC-DATA-INTEGRITY": {
            title:    "Verifiable Credential Data Integrity 1.0",
            href:     "https://www.w3.org/TR/vc-data-integrity/",
            authors:  ["David Longley", "Manu Sporny"],
            status:   "Working Draft",
            publisher:  "W3C Verifiable Credentials Working Group"
          },
          "DI-ECDSA": {
              title:    "The Elliptic Curve Digital Signature Algorithm Cryptosuites v1.0",
              href:     "https://www.w3.org/TR/vc-di-ecdsa/",
              authors:  ["David Longley", "Manu Sporny", "Marty Reed"],
              status:   "WD",
              publisher:  "W3C Verifiable Credentials Working Group"
          },
          "JSON-LD-FRAMING": {
            title:    "JSON-LD 1.1 Framing",
            href:     "https://www.w3.org/TR/json-ld11-framing",
            authors:  ["Dave Longley", "Gregg Kellogg", "Pierre-Antoine Champin"],
            status:   "Candidate Recommendation",
            publisher:  "W3C"
          },
          "JSON-LD": {
            title:    "JSON-LD 1.1",
            href:     "https://www.w3.org/TR/json-ld11",
            authors:  ["Dave Longley", "Gregg Kellogg", "Pierre-Antoine Champin"],
            status:   "Candidate Recommendation",
            publisher:  "W3C"
          },
          "VC-DATA-MODEL-2": {
            title: "Verifiable Credentials Data Model v2.0",
            href: "https://www.w3.org/TR/vc-data-model-2.0/",
            authors: [
              "Manu Sporny", "Dave Longley", "Grant Noble", "Dan Burnett",
              "Ted Thibodeau", "Brent Zundel", "David Chadwick",
              "Kyle Den Hartog"
            ],
            status: "Working Draft",
            publisher: "W3C Verifiable Credentials Working Group"
          },
          MULTIBASE: {
            title: "Multibase",
            href: "https://tools.ietf.org/html/draft-multiformats-multibase-01",
          },
          MULTICODEC: {
            title: "Multicodec",
            href: "https://github.com/multiformats/multicodec/",
          },
          "CFRG-BBS-SIGNATURE": {
            title:    "The BBS Signature Scheme",
            href:     "https://www.ietf.org/archive/id/draft-irtf-cfrg-bbs-signatures-02.html",
            authors:  ["Tobias Looker", "Vasilis Kalos", "Andrew Whitehead", "Mike Lodder"],
            status:   "Draft"
          },
          "BLS-JOSE-COSE": {
            title:    "Barreto-Lynn-Scott Elliptic Curve Key Representations for JOSE and COSE",
            href:     "https://datatracker.ietf.org/doc/draft-ietf-cose-bls-key-representations/",
            authors:  ["Michael B. Jones", "Tobias Looker"],
            status:   "Draft"
          }
        },
        lint: {"no-unused-dfns": false},
        postProcess: [restrictRefs]
      };
    </script>
        <style>
          pre .highlight {
            font-weight: bold;
            color: green;
          }
          pre .comment {
            font-weight: bold;
            color: Gray;
          }
          .color-text {
            font-weight: bold;
            text-shadow: -1px 0 black, 0 1px black, 1px 0 black, 0 -1px black;
          }
          ol.algorithm {
            counter-reset: numsection;
            list-style-type: none;
          }
          ol.algorithm li {
            margin: 0.5em 0;
          }
          ol.algorithm li:before {
            font-weight: bold;
            counter-increment: numsection;
            content: counters(numsection, ".") ") ";
          }
              </style>
  </head>
  <body>
    <section id='abstract'>
      <p>
This specification describes a Data Integrity Cryptosuite for use when generating
digital signatures using the BBS signature scheme.
The Signature Suite utilizes BBS signatures to provide selective disclosur and
unlinkable derived proofs.
      </p>
    </section>

    <section id='sotd'>
      <p>
This is an experimental specification and is undergoing regular revisions. It
is not fit for production deployment.
      </p>
    </section>

    <section>
      <h2>Introduction</h2>
      <p>
This specification defines a cryptographic suite for the purpose of
creating, verifying and deriving proofs using the BBS Signature Scheme in
conformance with the Data Integrity [[VC-DATA-INTEGRITY]] specification. The
BBS signature scheme directly provides for selective disclosure and unlinkable
proofs. It provides four high level functions that work within the issuer,
holder, verifier model. In particular an issuer uses the BBS `Sign` function to
create a cryptographic value known as a "BBS signature" which is used in signing
the original credential. A holder, on receipt of
a credential signed with BBS, then verifies the credential with the BBS `Verify`
function.
      </p>
      <p>
The holder then chooses information to selectively disclose from the
received credential and uses the BBS `ProofGen` function to generate a
cryptographic value, known as a "BBS proof" which is used in creating a proof
for this "derived credential". The cryptographic "BBS proof" value is unlinkable
to the original "BBS signature" and a different, unlinkable "BBS proof" can be
generated by the holder for additional "derived credentials", including those
containing the exact same information.
Finally, a verifier uses the BBS `ProofVerify` function to verify the derived
credential received from the holder.
      </p>
      <p>
To apply the BBS signature scheme to verifiable credentials involves the
processing specified in this document.
In general the suite uses the RDF Dataset Normalization Algorithm
[[RDF-DATASET-NORMALIZATION]] to transform an input document into its canonical
form. An issuer then uses selective disclosure primitives to separate the
canonical form into mandatory and non-mandatory statements. These are processed
separately with other information to serve as the inputs to the BBS `Sign`
function along with appropriate key material. This output is used to
generate a secured credential. A holder uses a set of selective disclosure
functions and the BBS `Verify` function on receipt of the credential
to ascertain validity.
      </p>
      <p>
Similarly, a holder on receipt of a BBS signed credential uses the RDF Dataset
Normalization Algorithm [[RDF-DATASET-NORMALIZATION]] to transform an input
document into its canonical form  and then applies selective disclosure
primitives to separate the canonical form into mandatory and selectively
disclosed statements which are appropriately processed and serve as inputs to
the BBS `ProofGen` function. The output of this function suitably processed
becomes the signed selectively disclosed credential sent to a verifier. Using
canonicalization and selective disclosure primitives the verifier can then use
the BBS `verifyProof` function to validate the credential.
      </p>

      <section id="terminology">
        <h3>Terminology</h3>

        <div data-include="https://w3c.github.io/vc-data-integrity/terms.html"></div>

      </section>



      <section id="conformance">
        <p>
A <dfn>conforming proof</dfn> is any concrete expression of the data model
that complies with the normative statements in this specification. Specifically,
all relevant normative statements in Sections
<a href="#data-model"></a> and <a href="#algorithms"></a>
of this document MUST be enforced.
        </p>

        <p>
A <dfn class="lint-ignore">conforming processor</dfn> is any algorithm realized
as software and/or hardware that generates or consumes a
<a>conforming proof</a>. Conforming processors MUST produce errors when
non-conforming documents are consumed.
        </p>
	<p>
This document contains examples of JSON and JSON-LD data. Some of these examples
are invalid JSON, as they include features such as inline comments (`//`)
explaining certain portions and ellipses (`...`) indicating the omission of
information that is irrelevant to the example. Such parts need to be
removed if implementers want to treat the examples as valid JSON or JSON-LD.
        </p>
      </section>
    </section>

    <section>
      <h2>Data Model</h2>

      <p>
The following sections outline the data model that is used by this specification
for <a>verification methods</a> and <a>data integrity proof</a> formats.
      </p>

      <section>
        <h2>Verification Methods</h2>
        <p>
These verification methods are used to verify Data Integrity Proofs
[[VC-DATA-INTEGRITY]] produced using BLS12-381 cryptographic key material
that is compliant with [[CFRG-BBS-SIGNATURE]]. The encoding formats for these key types
are provided in this section. Lossless cryptographic key transformation
processes that result in equivalent cryptographic key material MAY be used
during the processing of digital signatures.
        </p>
        <section>
          <h3>Multikey</h3>
          <p>
The <a data-cite="VC-DATA-INTEGRITY#multikey">Multikey format</a>, as defined in
[[VC-DATA-INTEGRITY]], is used to express public keys for the cryptographic
suites defined in this specification.
          </p>

          <p>
The `publicKeyMultibase` property represents a Multibase-encoded Multikey
expression of a BLS12-381 public key in the G2 group. The encoding this field is
the two-byte prefix `0xeb01` followed
by the 96-byte compressed public key data.
The 98-byte value is then encoded using base58-btc (`z`) as the prefix. Any
other encodings MUST NOT be allowed.
          </p>

          <p class="advisement">
Developers are advised to not accidentally publish a representation of a private
key. Implementations of this specification will raise errors in the event of a
[[?MULTICODEC]] value other than `0xeb01` being used in a
`publicKeyMultibase` value.
          </p>

          <pre class="example"
            title="An BLS12-381 G2 group public key, encoded as a Multikey">
{
  "id": "https://example.com/issuer/123#key-0",
  "type": "Multikey",
  "controller": "https://example.com/issuer/123",
  "publicKeyMultibase": "zUC7EK3ZakmukHhuncwkbySmomv3FmrkmS36E4Ks5rsb6VQSRpoCrx6
  Hb8e2Nk6UvJFSdyw9NK1scFXJp21gNNYFjVWNgaqyGnkyhtagagCpQb5B7tagJu3HDbjQ8h
  5ypoHjwBb"
}
          </pre>

          <pre class="example" title="A BLS12-381 G2 group public key,
          encoded as a Multikey in a controller document">
{
  "@context": [
    "https://www.w3.org/ns/did/v1",
    "https://w3id.org/security/data-integrity/v1"
  ],
  "id": "https://example.com/issuer/123",
  "verificationMethod": [{
    "id": "https://example.com/issuer/123#key-1",
    "type": "Multikey",
    "controller": "https://example.com/issuer/123",
    "publicKeyMultibase": "zUC7EK3ZakmukHhuncwkbySmomv3FmrkmS36E4Ks5rsb6VQSRpoCr
    x6Hb8e2Nk6UvJFSdyw9NK1scFXJp21gNNYFjVWNgaqyGnkyhtagagCpQb5B7tagJu3HDbjQ8h
    5ypoHjwBb"
  }]
}
          </pre>
        </section>
      </section>

      <section>
        <h2>Proof Representations</h2>

        <p>
This suite relies on detached digital signatures represented using [[MULTIBASE]]
and [[?MULTICODEC]].
        </p>

        <section>
          <h3>DataIntegrityProof</h3>

          <p>
The `verificationMethod` property of the proof MUST be a URL.
Dereferencing the `verificationMethod` MUST result in an object
containing a `type` property with the value set to
`Multikey`.
          </p>

          <p>
The `type` property of the proof MUST be `DataIntegrityProof`.
          </p>
          <p>
The `cryptosuite` property of the proof MUST be `bbs-2023`.
          </p>
          <p>
The `created` property of the proof MUST be an [[XMLSCHEMA11-2]]
formatted date string.
          </p>
          <p>
The `proofPurpose` property of the proof MUST be a string, and MUST
match the verification relationship expressed by the verification method
`controller`.
          </p>
          <p>
The value of the `proofValue` property of the proof MUST be an BBS signature or
BBS proof produced according to [[CFRG-BBS-SIGNATURE]] then serialized and encoded
according to procedures in section <a href="#algorithms"></a>.
          </p>
        </section>
      </section>

    </section>

    <section>
      <h2>Algorithms</h2>

      <p>
The following algorithms describe how to use verifiable credentials with
the BBS Signature Scheme [[CFRG-BBS-SIGNATURE]]. When using the BBS signature
scheme the SHAKE-256 variant SHOULD be used.
      </p>

      <p>
Implementations SHOULD fetch and cache <a>verification method</a> information as
early as possible when adding or verifying proofs. Parameters passed to
functions in this section use information from the <a>verification
method</a> — such as the public key size — to determine function parameters — such
as the cryptographic hashing algorithm.
      </p>

      <p class="advisement">
When the RDF Dataset Canonicalization Algorithm [[RDF-CANON]] is used,
implementations of that algorithm will detect
<a data-cite="RDF-CANON#dataset-poisoning">dataset poisoning</a>
by default, and abort processing upon detection.
      </p>

      <section>
        <h3>Selective Disclosure Functions</h3>

        <section>
          <h4>createShuffledIdLabelMapFunction</h4>
          <p class="issue">TODO: write details</p>
        </section>

        <p class="issue">
TODO: Fill in after section <a href="#bbs-2023-functions"></a> is completed.
        </p>
      </section>

      <section>
        <h3>bbs-2023 Functions</h3>
        <section>
          <h4>serializeBaseProofValue</h4>

          <p>
The following algorithm serializes the base proof value, including the
BBS signature, HMAC key, and mandatory pointers.
The required inputs are a base signature <var>bbsSignature</var>,
an HMAC key <var>hmacKey</var>, and an array of
<var>mandatoryPointers</var>.
A single <em>base proof</em> string value is produced as output.
                      </p>

                      <ol class="algorithm">
                        <li>
Initialize a byte array, `proofValue`, that starts with the BBS base proof
header bytes 0xd9, 0x5d, and 0x02.
                        </li>
                        <li>
Initialize `components` to an array with five elements containing the values of:
`bbsSignature`, `hmacKey`, and `mandatoryPointers`.
                        </li>
                        <li>
CBOR-encode `components` and append it to `proofValue`.
                        </li>
                        <li>
Initialize `baseProof` to a string with the multibase-base64url-no-pad-encoding
of `proofValue`. That is, return a string starting with "u" and ending with the
base64url-no-pad-encoded value of `proofValue`.
                        </li>
                        <li>
Return `baseProof` as <em>base proof</em>.
                        </li>
                      </ol>

        </section>

        <section>
          <h4>parseBaseProofValue</h4>


          <p>
The following algorithm parses the components of an `bbs-2023` selective
disclosure base proof value. The required inputs are a proof value
(<var>proofValue</var>). A single object <em>parsed base proof</em>, containing
three elements, using the names "bbsSignature", "hmacKey",
and "mandatoryPointers", is produced  as output.
          </p>

          <ol class="algorithm">
            <li>
Ensure the `proofValue` string starts with `u`, indicating that it is a
multibase-base64url-no-pad-encoded value, throwing an error if it does not.
            </li>
            <li>
Initialize `decodedProofValue` to the result of base64url-no-pad-decoding the
substring after the leading `u` in `proofValue`.
            </li>
            <li>
Ensure that the `decodedProofValue` starts with the BBS base proof header
bytes 0xd9, 0x5d, and 0x02, throwing an error if it does not.
            </li>
            <li>
Initialize `components` to an array that is the result of CBOR-decoding the
bytes that follow the three-byte ECDSA-SD base proof header. Ensure the result
is an array of three elements.
            </li>
            <li>
Return an object with properties set to the three elements, using the names
"bbsSignature", "hmacKey", and "mandatoryPointers",
respectively.
            </li>
          </ol>

        </section>

        <section>
          <h4>createDisclosureData</h4>

          <p>
The following algorithm creates data to be used to generate a derived proof. The
inputs include a JSON-LD document (<var>document</var>), an BBS base proof
(<var>proof</var>), an array of JSON pointers to use to selectively disclose
statements (<var>selectivePointers</var>), and any custom JSON-LD API options,
such as a document loader). A single object, <em>disclosure data</em>, is
produced as output, which contains the "bbsProof", "labelMap",
"mandatoryIndexes", "selectiveIndexes", and "revealDocument" fields.
          </p>

          <ol class="algorithm">
            <li>
Initialize `bbsSignature`, `hmacKey`,  and
`mandatoryPointers` to the values of the associated properties in the object
returned when calling the algorithm in Section
<a href="#parsebaseproofvalue"></a>, passing the `proofValue` from `proof`.
            </li>
            <li>
Initialize `hmac` to an HMAC API using `hmacKey`. The HMAC uses the same hash
algorithm used in the signature algorithm, i.e., SHAKE-256.
            </li>
            <li>
Initialize `labelMapFactoryFunction` to the result of calling the
`createShuffledIdLabelMapFunction` algorithm passing `hmac` as `HMAC`.
            </li>
            <li>
Initialize `combinedPointers` to the concatenation of `mandatoryPointers`
and `selectivePointers`.
            </li>
            <li>
Initialize `groupDefinitions` to a map with the following entries: key of
the string `"mandatory"` and value of `mandatoryPointers`, key of the string
`"selective"` and value of `selectivePointers`, and key of the string `"combined"`
and value of `combinedPointers`.
            </li>
            <li>
Initialize `groups` and `labelMap` to the result of calling the algorithm in
<a href="https://www.w3.org/TR/vc-di-ecdsa/#canonicalizeandgroup">Section 3.3.16
canonicalizeAndGroup</a> of the [[DI-ECDSA]] specification, passing `document`
`labelMapFactoryFunction`,
`groupDefinitions`, and any custom JSON-LD
API options. Note: This step transforms the document into an array of canonical
N-Quads whose order has been shuffled based on 'hmac' applied blank node
identifiers, and groups
the N-Quad strings according to selections based on JSON pointers.
            </li>

            <li>
Compute the mandatory indexes relative to their positions in the combined
statement list, i.e., find at what position a mandatory statement occurs in the
list of combined statements. One method for doing this is given below.
              <ol class="algorithm">
                <li>
Initialize `mandatoryIndexes` to an empty array. Set `mandatoryMatch` to
`groups.mandatory.matching` map, set `combinedMatch` to
`groups.combined.matching`, and set `combinedIndexes` to the ordered array of
just the keys of the `combinedMatch` map.
                </li>
                <li>
For each key in the `mandatoryMatch` map find its index in the `combinedIndexes`
array, e.g., `combinedIndexes.indexOf(key)`, and add this value to the
`mandatoryIndexes` array.
                </li>
              </ol>
            </li>
            <li>
Compute the selective indexes relative to their positions in the non-mandatory
statement list, i.e., find at what position a selected statement occurs in the
list of non-mandatory statements. One method for doing this is given below.
              <ol class="algorithm">
                <li>
Initialize `selectiveIndexes` to an empty array. Set `selectiveMatch` to the
`groups.selective.matching` map, set  `mandatoryNonMatch` to the map
`groups.mandatory.nonMatching`, and `nonMandatoryIndexes` to to the ordered array of
just the keys of the `mandatoryNonMatch` map.
                </li>
                <li>
For each key in the `selectiveMatch` map find its index in the `nonMandatoryIndexes`
array, e.g., `nonMandatoryIndexes.indexOf(key)`, and add this value to the
`selectiveIndexes` array.
                </li>
              </ol>
            </li>

            <li>
Initialize `bbsMessages` to an array of byte arrays obtained from the
UTF-8 encoding of the the values in the `nonMandatory` array.
            </li>
            <li>
Recompute the `bbsHeader` using the following steps:

              <ol class="algorithm">
                <li>
Initialize `proofHash` to the result of calling the RDF Dataset Canonicalization
algorithm [[RDF-CANON]] on `proof` with the `proofValue` removed and then
cryptographically
hashing the result using the same hash that is used by the signature algorithm,
i.e., SHAKE-256. Note: This step can be performed in parallel;
it only needs to be completed before this algorithm terminates as the result is
part of the return value.
                </li>
                <li>
Initialize `mandatoryHash` to the result of calling the the algorithm in
<a href="https://www.w3.org/TR/vc-di-ecdsa/#hashmandatorynquads">Section 3.3.17
hashMandatoryNQuads</a> of the [[DI-ECDSA]] specification, passing the values
from the map
<var>groups.mandatory.matching</var> and utilizing the SHAKE-256 algorithm.
                </li>
                <li>
Set  `bbsHeader` to the concatenation of `proofHash` and `mandatoryHash` in that
order.
                </li>
              </ol>
            </li>

            <li>
Set `bbsProof` to the value computed by the `ProofGen` procedure from
[[CFRG-BBS-SIGNATURE]], i.e. `ProofGen(PK, signature, header, ph, messages, disclosed_indexes)`,
where `PK` is the original issuers public key, `signature` is the
`bbsSignature`, `header` is the `bbsHeader`, `ph` is an empty byte array,
`messages` is `bbsMessages` and `disclosed_indexes` is `selectiveIndexes`.
            </li>

            <li>
Initialize <var>revealDocument</var> to the result of the "selectJsonLd"
algorithm, passing `document`, and `combinedPointers` as `pointers`.
            </li>
            <li>
Run the RDF Dataset Canonicalization Algorithm [[RDF-CANON]] on
the joined <var>combinedGroup.deskolemizedNQuads</var>, passing any custom
options, and get the canonical bnode identifier map, <var>canonicalIdMap</var>.
Note: This map includes the canonical blank node identifiers that a verifier
will produce when they canonicalize the reveal document.
            </li>
            <li>
Initialize <var>verifierLabelMap</var> to an empty map. This map will map
the canonical blank node identifiers the verifier will produce when they
canonicalize the revealed document to the blank node identifiers that were
originally signed in the base proof.
            </li>
            <li>
For each key (`inputLabel`) and value (`verifierLabel`) in `canonicalIdMap:
              <ol class="algorithm">
                <li>
Add an entry to `verifierLabelMap` using `verifierLabel` as the key and the
value associated with `inputLabel` as a key in `labelMap` as the value.
                </li>
              </ol>
            </li>
            <li>
Return an object with properties matching `bbsProof`,  "verifierLabelMap" for `labelMap`,
`mandatoryIndexes`, `selectiveIndexes` and `revealDocument`.
            </li>
          </ol>

        </section>

        <section>
          <h4>serializeDerivedProofValue</h4>
        </section>
        <section>
          <h4>createVerifyData</h4>
        </section>
        <p class="issue">
TODO: Fill in after section <a href="#bbs-2023"></a> is completed.
        </p>
      </section>

      <section>
        <h3>bbs-2023</h3>

        <p>
The `bbs-2023` cryptographic suite takes an input document, canonicalizes
the document using the Universal RDF Dataset Canonicalization Algorithm
[[RDF-CANON]], and then applies a number of transformations and cryptographic
operations resulting in the production of a data integrity proof. The algorithms
in this section also include the verification of such a data integrity proof.
        </p>

        <section>
          <h4>Add Base Proof (bbs-2023)</h4>

          <p>
To generate a base proof, the algorithm in
<a href="https://www.w3.org/TR/vc-data-integrity/#add-proof">
Section 4.1: Add Proof</a> in the Data Integrity
[[VC-DATA-INTEGRITY]] specification MUST be executed.
For that algorithm, the cryptographic suite specific
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-transformation-algorithm">
transformation algorithm</a> is defined in Section
<a href="#base-proof-transformation-bbs-2023"></a>, the
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-hashing-algorithm">
hashing algorithm</a> is defined in Section <a href="#base-proof-hashing-bbs-2023"></a>,
and the
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-proof-serialization-algorithm">
proof serialization algorithm</a> is defined in Section
<a href="#base-proof-serialization-bbs-2023"></a>.
          </p>
        </section>

        <section>
          <h4>Base Proof Transformation (bbs-2023)</h4>
          <p>
The following algorithm specifies how to transform an unsecured input document
into a transformed document that is ready to be provided as input to the
hashing algorithm in Section <a href="#base-proof-hashing-bbs-2023"></a>.
          </p>
          <p>
Required inputs to this algorithm are an
<a data-cite="vc-data-integrity#dfn-unsecured-data-document">
unsecured data document</a> (<var>unsecuredDocument</var>) and
transformation options (<var>options</var>). The
transformation options MUST contain a type identifier for the
<a data-cite="vc-data-integrity#dfn-cryptosuite">
cryptographic suite</a> (<var>type</var>), a cryptosuite
identifier (<var>cryptosuite</var>), and a verification method
(<var>verificationMethod</var>). The transformation options MUST contain an
array of mandatory JSON pointers (<var>mandatoryPointers</var>) and MAY contain
additional options, such as a JSON-LD document loader. A <em>transformed data
document</em> is produced as output. Whenever this algorithm encodes strings, it
MUST use UTF-8 encoding.
          </p>
          <ol class="algorithm">
            <li>
Initialize `hmac` to an HMAC API using a locally generated and exportable HMAC
key. The HMAC uses the same hash algorithm used in the signature algorithm,
i.e., SHAKE-256.
            </li>
            <li>
Initialize `labelMapFactoryFunction` to the result of calling the
`createShuffledIdLabelMapFunction` algorithm passing `hmac` as `HMAC`.
            </li>
            <li>
Initialize `groupDefinitions` to a map with an entry with a key of the string
"mandatory" and a value of <var>mandatoryPointers</var>.
            </li>
            <li>
Initialize `groups` to the result of calling the algorithm in
<a href="https://www.w3.org/TR/vc-di-ecdsa/#canonicalizeandgroup">Section 3.3.16
canonicalizeAndGroup</a> of the [[DI-ECDSA]] specification, passing
`labelMapFactoryFunction`,
`groupDefinitions`, `unsecuredDocument` as `document`, and any custom JSON-LD
API options. Note: This step transforms the document into an array of canonical
N-Quads whose order has been shuffled based on 'hmac' applied blank node
identifiers, and groups
the N-Quad strings according to selections based on JSON pointers.
            </li>
            <li>
Initialize `mandatory` to the values in the `groups.mandatory.matching` map.
            </li>
            <li>
Initialize `nonMandatory` to the values in the `groups.mandatory.nonMatching`
map.
            </li>
            <li>
Initialize `hmacKey` to the result of exporting the HMAC key from `hmac`.
            </li>
            <li>
Return an object with "mandatoryPointers" set to `mandatoryPointers`,
"mandatory" set to `mandatory`, "nonMandatory" set to `nonMandatory`,
and "hmacKey" set to `hmacKey`.
            </li>
          </ol>
        </section>

        <section>
          <h4>Base Proof Hashing (bbs-2023)</h4>

          <p>
The following algorithm specifies how to cryptographically hash a
<em>transformed data document</em> and <em>proof configuration</em>
into cryptographic hash data that is ready to be provided as input to the
algorithms in Section <a href="#base-proof-serialization-bbs-2023"></a>.
          </p>

          <p>
The required inputs to this algorithm are a <em>transformed data document</em>
(<var>transformedDocument</var>) and <em>canonical proof configuration</em>
(<var>canonicalProofConfig</var>). A <em>hash data</em> value represented
as an object is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Initialize `proofHash` to the result of calling the RDF Dataset Canonicalization
algorithm [[RDF-CANON]] on `canonicalProofConfig` and then cryptographically
hashing the result using the same hash that is used by the signature algorithm,
i.e., SHAKE-256. Note: This step can be performed in parallel;
it only needs to be completed before this algorithm terminates as the result is
part of the return value.
            </li>
            <li>
Initialize `mandatoryHash` to the result of calling the the algorithm in
<a href="https://www.w3.org/TR/vc-di-ecdsa/#hashmandatorynquads">Section 3.3.17
hashMandatoryNQuads</a> of the [[DI-ECDSA]] specification, passing
<var>transformedDocument</var>.`mandatory` and utilizing the SHAKE-256
algorithm.
            </li>
            <li>
Initialize `hashData` as a deep copy of <var>transformedDocument</var> and
add `proofHash` as "proofHash" and `mandatoryHash` as "mandatoryHash" to that
object.
            </li>
            <li>
Return `hashData` as <em>hash data</em>.
            </li>
          </ol>

        </section>

        <section>
          <h4>Base Proof Configuration (bbs-2023)</h4>

          <p>
The following algorithm specifies how to generate a
<em>proof configuration</em> from a set of <em>proof options</em>
that is used as input to the
<a href="#base-proof-hashing-bbs-2023">base proof hashing algorithm</a>.
          </p>

          <p>
The required inputs to this algorithm are <em>proof options</em>
(<var>options</var>). The <em>proof options</em> MUST contain a type identifier
for the
<a data-cite="vc-data-integrity#dfn-cryptosuite">
cryptographic suite</a> (<var>type</var>) and MUST contain a cryptosuite
identifier (<var>cryptosuite</var>). A <em>proof configuration</em>
object is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Let <var>proofConfig</var> be an empty object.
            </li>
            <li>
Set <var>proofConfig</var>.<var>type</var> to
<var>options</var>.<var>type</var>.
            </li>
            <li>
If <var>options</var>.<var>cryptosuite</var> is set, set
<var>proofConfig</var>.<var>cryptosuite</var> to its value.
            </li>
            <li>
If <var>options</var>.<var>type</var> is not set to `DataIntegrityProof` and
<var>proofConfig</var>.<var>cryptosuite</var> is not set to `bbs-2023`, an
`INVALID_PROOF_CONFIGURATION` error MUST be raised.
            </li>
            <li>
Set <var>proofConfig</var>.<var>created</var> to
<var>options</var>.<var>created</var>. If the value is not a valid
[[XMLSCHEMA11-2]] datetime, an `INVALID_PROOF_DATETIME` error MUST be raised.
            </li>
            <li>
Set <var>proofConfig</var>.<var>verificationMethod</var> to
<var>options</var>.<var>verificationMethod</var>.
            </li>
            <li>
Set <var>proofConfig</var>.<var>proofPurpose</var> to
<var>options</var>.<var>proofPurpose</var>.
            </li>
            <li>
Set <var>proofConfig</var>.<var>@context</var> to
<var>unsecuredDocument</var>.<var>@context</var>.
            </li>
            <li>
Let <var>canonicalProofConfig</var> be the result of applying the
Universal RDF Dataset Canonicalization Algorithm
[[RDF-CANON]] to the <var>proofConfig</var>.
            </li>
            <li>
Return <var>canonicalProofConfig</var>.
            </li>
          </ol>

        </section>


        <section>
          <h4>Base Proof Serialization (bbs-2023)</h4>

          <p>
The following algorithm specifies how to create a base proof; called by an
issuer of an BBS-protected Verifiable Credential. The base proof is to be
given only to the holder, who is responsible for generating a derived proof from
it, exposing only selectively disclosed details in the proof to a verifier. This
algorithm is designed to be used in conjunction with the algorithms defined
in the Data Integrity [[VC-DATA-INTEGRITY]] specification,
<a data-cite="vc-data-integrity#algorithms">
Section 4: Algorithms</a>. Required inputs are
cryptographic hash data (<var>hashData</var>) and
<em>proof options</em> (<var>options</var>). The
<em>proof options</em> MUST contain a type identifier for the
<a data-cite="vc-data-integrity#dfn-cryptosuite">
cryptographic suite</a> (<var>type</var>) and MAY contain a cryptosuite
identifier (<var>cryptosuite</var>). A single <em>digital proof</em> value
represented as series of bytes is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Initialize `proofHash`, `mandatoryPointers`, `mandatoryHash`, `nonMandatory`,
and `hmacKey` to the values associated with their property names in
<var>hashData</var>.
            </li>
            <li>
Initialize `bbsHeader` to the concatenation of `proofHash` and `mandatoryHash` in
that order.
            </li>
            <li>
Initialize `bbsMessages` to an array of byte arrays obtained from the
UTF-8 encoding of the the values in the `nonMandatory` array.
            </li>
            <li>
Compute the `bbsSignature` using the `Sign` procedure of [[CFRG-BBS-Signature]]
with appropriate key material and `bbsHeader` for the `header` and `bbsMessages`
for the `messages`
            </li>
            <li>
Initialize `proofValue to the result of calling the algorithm in Section
<a href="#serializebaseproofvalue"></a>, passing `bbsSignature`,
`hmacKey`, and `mandatoryPointers` as parameters
to the algorithm.
            </li>
            <li>
Return `proofValue` as <em>digital proof</em>.
            </li>
          </ol>
        </section>


        <section>
          <h4>Add Derived Proof (bbs-2023)</h4>

          <p>
The following algorithm creates a selective disclosure derived proof; called by
a holder of an `bbs-2023`-protected <a>verifiable credential</a>.
The derived proof is to be given to the <a>verifier</a>. The inputs include a
JSON-LD document (<var>document</var>), a BBS base proof
(<var>proof</var>), an array of JSON pointers to use to selectively disclose
statements (<var>selectivePointers</var>), and any custom JSON-LD API options,
such as a document loader. A single <em>selectively revealed document</em>
value, represented as an object, is produced as output.
          </p>

          <ol>
            <li>
Initialize `bbsProof`,  `labelMap`, `mandatoryIndexes`, `selectiveIndexes`, and
`revealDocument` to the values associated with their
property names in the object returned when calling the algorithm in
Section <a href="#createdisclosuredata"></a>, passing the `document`, `proof`,
`selectivePointers`, and any custom JSON-LD API options, such as a document
loader.
            </li>
            <li>
Initialize `newProof` to a shallow copy of `proof`.
            </li>
            <li>
Replace `proofValue` in `newProof` with the result of calling the algorithm
in Section <a href="#serializederivedproofvalue"></a>, passing `bbsProof`,
`labelMap`, `mandatoryIndexes`, and `selectiveIndexes`.
            </li>
            <li>
Set the value of the "proof" property in `revealDocument` to `newProof`.
            </li>
            <li>
Return `revealDocument` as the <em>selectively revealed document</em>.
            </li>
          </ol>

        </section>


        <section>
          <h4>Verify Derived Proof (bbs-2023)</h4>

          <p>
The following algorithm attempts verification of a `bbs-2023` derived
proof. This algorithm is called by a verifier of an BBS-protected
<a>verifiable credential</a>. The inputs include a JSON-LD document
(<var>document</var>), an BBS disclosure proof (<var>proof</var>), and any
custom JSON-LD API options, such as a document loader. A single boolean
<em>verification result</em> value is produced as output.
          </p>

          <ol class="algorithm">
            <!-- [bbsProof, labelMapCompressed, mandatoryIndexes, adjSelectedIndexes] -->
            <li>
Initialize `bbsProof`, `proofHash`, `mandatoryHash`, `selectedIndexes`, and
`nonMandatory` to the values associated with their property
names in the object returned when calling the algorithm in Section
<a href="#createverifydata"></a>, passing the `document`, `proof`, and any
custom JSON-LD API options, such as a document loader.
            </li>
            <li>
Initialize `bbsHeader` to the concatenation of `proofHash` and `mandatoryHash`
in that order. Initialized `disclosedMessages` to an array of byte arrays
obtained from the UTF-8 encoding of the elements of the `nonMandatory` array.
            </li>
<!-- result = ProofVerify(PK, proof, header, ph, disclosed_messages, disclosed_indexes) -->
            <li>
Initialize `verificationResult` be the result of applying the verification
algorithm `ProofVerify` of [[CFRG-BBS-SIGNATURE]]
with `PK` the public key of the original issuer, `proof` set as `bbsProof`,
`header` set as `bbsHeader`, `disclosed_messages` set as `disclosedMessages`,
`ph` set as an empty byte array, and `disclosed_indexes` set as
`selectiveIndexes`. Return `verificationResult` as <em>verification result</em>.
            </li>
          </ol>

        </section>

      </section>

    </section>



    <section>
      <h2>Privacy Considerations</h2>
      <p class="issue">TODO: We need to add a complete list of privacy
      considerations.</p>
    </section>

    <section>
      <h2>Security Considerations</h2>
      <p class="issue">TODO: We need to add a complete list of security
      considerations.</p>
    </section>

    <section class="appendix">
      <h2>Acknowledgements</h2>
      <p>
        Portions of the work on this specification have been funded by the
        United States Department of Homeland Security's (US DHS) Silicon Valley
        Innovation Program under contracts
        70RSAT20T00000003,
        and
        70RSAT20T00000033.
        The content of this specification does not
        necessarily reflect the position or the policy of the U.S. Government
        and no official endorsement should be inferred.
      </p>
    </section>
  </body>
</html>
